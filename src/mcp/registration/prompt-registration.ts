/**
 * ServalSheets - Prompt Registration
 *
 * Guided workflows and templates for common operations.
 *
 * @module mcp/registration/prompt-registration
 */

import type { McpServer } from '@modelcontextprotocol/sdk/server/mcp.js';
import {
  FirstOperationPromptArgsSchema,
  AnalyzeSpreadsheetPromptArgsSchema,
  TransformDataPromptArgsSchema,
  CreateReportPromptArgsSchema,
  CleanDataPromptArgsSchema,
  MigrateDataPromptArgsSchema,
  SetupBudgetPromptArgsSchema,
  ImportDataPromptArgsSchema,
  SetupCollaborationPromptArgsSchema,
  DiagnoseErrorsPromptArgsSchema,
  SafeOperationPromptArgsSchema,
  BulkImportPromptArgsSchema,
  UndoChangesPromptArgsSchema,
  MasterClassDataQualityPromptArgsSchema,
  MasterClassFormulasPromptArgsSchema,
  MasterClassPerformancePromptArgsSchema,
  ChallengeQualityDetectivePromptArgsSchema,
  ChallengePerformanceProfilerPromptArgsSchema,
  ScenarioMultiUserPromptArgsSchema,
  AutoAnalyzePromptArgsSchema,
  FullSetupPromptArgsSchema,
  AuditSecurityPromptArgsSchema,
  CompareSpreadsheetPromptArgsSchema,
  RecoverFromErrorPromptArgsSchema,
  TroubleshootPerformancePromptArgsSchema,
  FixDataQualityPromptArgsSchema,
  OptimizeFormulasPromptArgsSchema,
  BulkImportDataPromptArgsSchema,
  AdvancedDataMigrationPromptArgsSchema,
  PerformanceAuditPromptArgsSchema,
  BatchOptimizerPromptArgsSchema,
  UltimateAnalysisPromptArgsSchema,
  CreateVisualizationPromptArgsSchema,
  AnalyzeWithHistoryPromptArgsSchema,
} from '../../schemas/prompts.js';

// ============================================================================
// PROMPTS REGISTRATION
// ============================================================================

/**
 * Registers ServalSheets prompts with the MCP server
 *
 * Prompts provide guided workflows and templates for common operations.
 *
 * @param server - McpServer instance
 */
export function registerServalSheetsPrompts(server: McpServer): void {
  // === ONBOARDING PROMPTS ===

  server.registerPrompt(
    'welcome',
    {
      description: 'ğŸ‰ Welcome to ServalSheets! Get started with this guided introduction.',
      argsSchema: {},
    },
    async () => {
      return {
        messages: [
          {
            role: 'user' as const,
            content: {
              type: 'text' as const,
              text: `ğŸ‰ Welcome to ServalSheets!

I'm your Google Sheets assistant with 21 powerful tools and 293 actions.

## ğŸš€ Quick Start
Test spreadsheet: \`1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms\`

## ğŸ“Š Capabilities
â€¢ Data Operations: Read, write, batch operations
â€¢ Analysis: Data quality, statistics, formula audit
â€¢ AI Analysis: Pattern detection, anomalies, formula generation (via MCP Sampling)
â€¢ Formatting: Colors, fonts, conditional formatting
â€¢ Advanced: Charts, pivots, sharing, versions

## ğŸ›¡ï¸ Safety Features
â€¢ Dry-run mode, effect limits, auto-snapshots
â€¢ User confirmation for multi-step operations (via MCP Elicitation)

What would you like to do first?`,
            },
          },
        ],
      };
    }
  );

  server.registerPrompt(
    'test_connection',
    {
      description: 'ğŸ” Test your ServalSheets connection with a public spreadsheet',
      argsSchema: {},
    },
    async () => {
      return {
        messages: [
          {
            role: 'user' as const,
            content: {
              type: 'text' as const,
              text: `ğŸ” Testing ServalSheets connection!

Test spreadsheet: 1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms

Please run these tests in order:
1. sheets_auth action: "status" â†’ Verify authentication
2. sheets_core action: "get", spreadsheetId: "1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms" â†’ Get metadata
3. sheets_data action: "read", spreadsheetId: "1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms", range: "Sheet1!A1:D10" â†’ Read sample data
4. sheets_analyze action: "analyze_structure", spreadsheetId: "1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms" â†’ Analyze structure

If all tests pass, you're ready to use ServalSheets!
If auth fails, follow the authentication flow first.`,
            },
          },
        ],
      };
    }
  );

  server.registerPrompt(
    'first_operation',
    {
      description: 'ğŸ‘¶ Your first ServalSheets operation - a guided walkthrough',
      argsSchema: FirstOperationPromptArgsSchema,
    },
    async (args: Record<string, unknown>) => {
      const spreadsheetId = args['spreadsheetId'] || '1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms';
      return {
        messages: [
          {
            role: 'user' as const,
            content: {
              type: 'text' as const,
              text: `ğŸ‘¶ First ServalSheets operation!

Spreadsheet: ${spreadsheetId}

Steps:
1. Read data: sheets_core action "get"
2. Analyze quality: sheets_analyze action "analyze_quality"
3. Get statistics: sheets_analyze action "analyze_data"
4. Format headers: sheets_format (use dryRun first!)

Safety tips: Always read before modify, use dryRun for destructive ops.`,
            },
          },
        ],
      };
    }
  );

  // === ANALYSIS PROMPTS ===

  server.registerPrompt(
    'analyze_spreadsheet',
    {
      description: 'ğŸ”¬ Comprehensive analysis of spreadsheet data quality and structure',
      argsSchema: AnalyzeSpreadsheetPromptArgsSchema,
    },
    async (args: Record<string, unknown>) => {
      return {
        messages: [
          {
            role: 'user' as const,
            content: {
              type: 'text' as const,
              text: `ğŸ”¬ Analyzing: ${args['spreadsheetId']}

**CONTEXT GATHERING PHASE** (Ask user before proceeding):
- What is this spreadsheet used for? (purpose helps focus analysis)
- Are there specific concerns? (data quality, formulas, performance)
- Which sheets should I prioritize? (or analyze all?)
- Any recent changes that might have caused issues?

**ANALYSIS EXECUTION** (After gathering context):
1. Metadata: sheets_core action "get" - understand structure
2. Data Quality: sheets_analyze action "analyze_quality" - find issues
3. Structure: sheets_analyze action "analyze_structure" - validate schema
4. Formula Audit: sheets_analyze action "analyze_formulas" - check for errors
5. AI Insights: sheets_analyze action "analyze_data" - intelligent patterns

**DELIVER RESULTS**:
- Quality score (0-100)
- Issues found (categorized by severity)
- Recommended fixes (prioritized by impact)
- Next steps based on user's stated purpose`,
            },
          },
        ],
      };
    }
  );

  server.registerPrompt(
    'transform_data',
    {
      description: 'ğŸ”„ Transform data in a spreadsheet range with safety checks',
      argsSchema: TransformDataPromptArgsSchema,
    },
    async (args: Record<string, unknown>) => {
      return {
        messages: [
          {
            role: 'user' as const,
            content: {
              type: 'text' as const,
              text: `ğŸ”„ Transform data

Spreadsheet: ${args['spreadsheetId']}
Range: ${args['range']}
Transform: ${args['transformation']}

Workflow:
1. Read current data
2. Plan transformation
3. Confirm with user (sheets_confirm via Elicitation)
4. Execute with safety limits
5. Verify results`,
            },
          },
        ],
      };
    }
  );

  server.registerPrompt(
    'create_report',
    {
      description: 'ğŸ“ˆ Generate a formatted report from spreadsheet data',
      argsSchema: CreateReportPromptArgsSchema,
    },
    async (args: Record<string, unknown>) => {
      const reportType = args['reportType'] || 'summary';
      return {
        messages: [
          {
            role: 'user' as const,
            content: {
              type: 'text' as const,
              text: `ğŸ“ˆ Creating ${reportType} report from ${args['spreadsheetId']}

Steps:
1. Read source data
2. Create "Report" sheet
3. Add summary statistics
4. Apply formatting
${reportType === 'charts' ? '5. Add charts (use sheets_analyze to suggest best chart types)\n' : ''}
Final: Auto-resize, freeze header, add timestamp`,
            },
          },
        ],
      };
    }
  );

  server.registerPrompt(
    'clean_data',
    {
      description: 'ğŸ§¹ Clean and standardize data in a spreadsheet range',
      argsSchema: CleanDataPromptArgsSchema,
    },
    async (args: Record<string, unknown>) => {
      return {
        messages: [
          {
            role: 'user' as const,
            content: {
              type: 'text' as const,
              text: `ğŸ§¹ Cleaning data: ${args['spreadsheetId']}, range ${args['range']}

**CONTEXT GATHERING PHASE** (Ask user before proceeding):
- What type of data is this? (contacts, sales, inventory, etc.)
- What cleaning operations are most important?
  â–¡ Remove duplicates
  â–¡ Fix empty cells (delete, fill, or flag?)
  â–¡ Standardize formats (dates, phone numbers, currencies)
  â–¡ Trim whitespace
  â–¡ Fix capitalization
- Should I preserve the original data? (create backup sheet?)
- Any values that should NOT be modified?

**CLEANING EXECUTION** (After gathering context):
1. Analyze: Run data quality check (sheets_analyze action "analyze_quality")
2. Plan: Identify issues based on user's priorities
3. Preview: Show sample changes before applying
4. Confirm: Request approval via sheets_confirm
5. Execute: Apply changes with auto-snapshot for undo
6. Validate: Report changes made with before/after comparison

**SAFETY NOTE**: All destructive operations require confirmation.
Original data preserved via snapshot for easy rollback.`,
            },
          },
        ],
      };
    }
  );

  // === NEW WORKFLOW PROMPTS ===

  server.registerPrompt(
    'migrate_data',
    {
      description: 'ğŸ“¦ Migrate data between spreadsheets with validation',
      argsSchema: MigrateDataPromptArgsSchema,
    },
    async (args: Record<string, unknown>) => {
      return {
        messages: [
          {
            role: 'user' as const,
            content: {
              type: 'text' as const,
              text: `ğŸ“¦ Data Migration

Source: ${args['sourceSpreadsheetId']} (${args['sourceRange']})
Target: ${args['targetSpreadsheetId']} (${args['targetRange'] || 'auto-detect'})

Migration Workflow:
1. Read source data: sheets_data action "read"
2. Validate data: Check schema, detect issues
3. Check target: Ensure compatibility
4. Plan operation: Present migration plan
5. Confirm: Use sheets_confirm for user approval
6. Execute: Copy data with transaction safety
7. Validate: Compare row counts, checksums

Safety: Creates snapshots of both sheets before migration.`,
            },
          },
        ],
      };
    }
  );

  server.registerPrompt(
    'setup_budget',
    {
      description: 'ğŸ’° Create a budget tracking spreadsheet with formulas and formatting',
      argsSchema: SetupBudgetPromptArgsSchema,
    },
    async (args: Record<string, unknown>) => {
      const budgetType = args['budgetType'] || 'personal';
      const spreadsheetId = args['spreadsheetId'];

      return {
        messages: [
          {
            role: 'user' as const,
            content: {
              type: 'text' as const,
              text: `ğŸ’° Setting up ${budgetType} budget tracker
${spreadsheetId ? `Spreadsheet: ${spreadsheetId}` : 'Creating new spreadsheet'}

**CONTEXT GATHERING PHASE** (Ask user before creating):
- What currency should I use? (USD, EUR, GBP, etc.)
- What time period? (monthly, yearly, both?)
- What income categories do you need?
  â–¡ Salary â–¡ Investments â–¡ Side income â–¡ Other (specify)
- What expense categories do you want?
  â–¡ Housing â–¡ Utilities â–¡ Food â–¡ Transport â–¡ Entertainment â–¡ Savings â–¡ Other (specify)
- Do you want to track by date or just totals?
- Should I include goal tracking? (savings targets, debt payoff)
- Do you need multi-person support? (family budget)

**BUDGET SETUP** (After gathering preferences):
1. Create structure:
   - Income sheet: User's categories, amounts, dates
   - Expenses sheet: User's categories, amounts, dates
   - Summary sheet: Totals, remaining, visualizations

2. Add formulas (customized to user's needs):
   - SUMIF for category totals
   - Date filters for selected time period
   - Budget vs actual calculations
   - Goals progress tracking (if requested)

3. Format cells:
   - Currency format (user's selected currency)
   - Conditional formatting: red for overspent, green for under
   - Freeze headers, alternating row colors

4. Add charts:
   - Pie chart: Expense breakdown by category
   - Line chart: Monthly trends over time
   - Progress bar: Goal tracking (if requested)

5. Setup validation:
   - Dropdowns for user's categories
   - Date validation
   - Positive number validation

Final: Professional formatting + instructions sheet with examples.`,
            },
          },
        ],
      };
    }
  );

  server.registerPrompt(
    'import_data',
    {
      description: 'ğŸ“¥ Import external data into Google Sheets with transformation',
      argsSchema: ImportDataPromptArgsSchema,
    },
    async (args: Record<string, unknown>) => {
      return {
        messages: [
          {
            role: 'user' as const,
            content: {
              type: 'text' as const,
              text: `ğŸ“¥ Data Import Workflow

Spreadsheet: ${args['spreadsheetId']}
Data source: ${args['dataSource']}
Target: ${args['targetSheet'] || 'new sheet'}

Import Steps:
1. Prepare data:
   - Parse source format (CSV, JSON, API response)
   - Validate structure
   - Clean special characters

2. Create target sheet:
   - sheets_core action "add_sheet"
   - Name appropriately

3. Import data:
   - Use sheets_data action "write" or "append"
   - Handle large datasets (batch if > 10k rows)

4. Post-import:
   - Auto-format headers
   - Freeze top row
   - Auto-resize columns
   - Add data validation

5. Quality check:
   - Run sheets_analyze "analyze_quality"
   - Verify row counts
   - Check for import errors

Pro tip: Use sheets_transaction to batch all operations into 1 API call.`,
            },
          },
        ],
      };
    }
  );

  server.registerPrompt(
    'setup_collaboration',
    {
      description: 'ğŸ‘¥ Configure sharing and permissions for team collaboration',
      argsSchema: SetupCollaborationPromptArgsSchema,
    },
    async (args: Record<string, unknown>) => {
      const role = args['role'] || 'writer';
      const collaborators = args['collaborators'] as string[];

      return {
        messages: [
          {
            role: 'user' as const,
            content: {
              type: 'text' as const,
              text: `ğŸ‘¥ Setting up collaboration

Spreadsheet: ${args['spreadsheetId']}
Adding ${collaborators.length} collaborator(s) as "${role}"

Collaboration Setup:
1. Share spreadsheet:
   ${collaborators.map((email, i) => `   ${i + 1}. sheets_collaborate action "share_add", email: "${email}", role: "${role}"`).join('\n')}

2. Setup protected ranges:
   - Lock critical formulas/headers
   - sheets_advanced action "add_protected_range"
   - Allow editors to only edit data cells

3. Add version control:
   - Create initial snapshot
   - sheets_collaborate action "version_create_snapshot"

4. Setup comments:
   - Add collaboration guidelines comment
   - sheets_collaborate action "add"

5. Configure notifications:
   - Enable edit notifications
   - Setup comment alerts

Best practices:
- Use "commenter" role for stakeholders
- Use "writer" role for team members
- Reserve "owner" role transfers for handoffs`,
            },
          },
        ],
      };
    }
  );

  server.registerPrompt(
    'diagnose_errors',
    {
      description: 'ğŸ”§ Troubleshoot and diagnose spreadsheet issues',
      argsSchema: DiagnoseErrorsPromptArgsSchema,
    },
    async (args: Record<string, unknown>) => {
      const errorDesc = args['errorDescription'] || 'general diagnostics';

      return {
        messages: [
          {
            role: 'user' as const,
            content: {
              type: 'text' as const,
              text: `ğŸ”§ Diagnosing: ${errorDesc}

Spreadsheet: ${args['spreadsheetId']}

Diagnostic Workflow:
1. Basic checks:
   - sheets_core "get": Verify access
   - Check sheet count, total cells

2. Data quality:
   - sheets_analyze "analyze_quality": Find data issues
   - sheets_analyze "analyze_formulas": Check formula errors

3. AI analysis:
   - sheets_analyze "analyze": Deep pattern analysis
   - Detect anomalies, inconsistencies

4. Performance check:
   - Check formula complexity
   - Identify slow formulas (nested VLOOKUPs)
   - Recommend ARRAYFORMULA or INDEX/MATCH

5. Structure analysis:
   - sheets_analyze "analyze_structure"
   - Check for duplicate headers
   - Verify data types per column

Common Issues:
- #REF! errors: Deleted referenced cells
- #DIV/0!: Division by zero
- #N/A: VLOOKUP not found
- Circular references: Formula refers to itself
- Performance: Too many volatile functions (NOW, RAND)

Report:
- Issue summary
- Affected ranges
- Recommended fixes
- Preventive measures`,
            },
          },
        ],
      };
    }
  );

  // Error Recovery Prompt - AI-powered troubleshooting
  server.registerPrompt(
    'recover_from_error',
    {
      description:
        'ğŸ”§ Recover from ServalSheets errors - AI-powered troubleshooting and self-healing',
      argsSchema: RecoverFromErrorPromptArgsSchema,
    },
    async (args: Record<string, unknown>) => {
      const errorCode = (args['errorCode'] as string) || 'UNKNOWN_ERROR';
      const errorMessage = (args['errorMessage'] as string) || '';
      const toolName = (args['toolName'] as string) || '';
      const context = (args['context'] as string) || '';

      const recoveryGuide: Record<string, string> = {
        INTERNAL_ERROR: `ğŸ”´ INTERNAL_ERROR - Likely Fixed in v1.3.0-hotfix.1

This was the "taskStore.isTaskCancelled is not a function" bug.

âœ… Fix Applied:
- Task cancellation bug fixed
- Rebuild: npm run build
- Restart Claude Desktop completely (Cmd+Q then relaunch)

Verification:
1. node dist/cli.js --version (should show v1.3.0)
2. Check if error persists after restart
3. Logs: ~/Library/Logs/Claude/mcp*.log

If still occurring after restart:
â€¢ Verify dist/server.js contains "this.taskStore.isTaskCancelled"
â€¢ Check Claude Desktop config path is correct
â€¢ Try: rm -rf dist && npm run build`,

        QUOTA_EXCEEDED: `âš ï¸ QUOTA_EXCEEDED - Google API Rate Limit

Immediate Actions:
1. Wait 60 seconds before retry
2. Switch to batch operations (saves 80% quota):
   sheets_data action="batch_read" ranges=["A1:B2","D1:E2"]
   Instead of: Multiple individual "read" calls

Prevention:
â€¢ Check quota: sheets_auth action="status"
â€¢ Use semantic ranges: {"semantic":{"column":"Revenue"}}
â€¢ Batch operations: batch_read, batch_write, batch_update

Recovery Time: 60 seconds per 100 requests`,

        RANGE_NOT_FOUND: `âŒ RANGE_NOT_FOUND - Sheet or Range Doesn't Exist

Diagnosis:
1. List all sheets: sheets_core action="list_sheets"
2. Check exact spelling (case-sensitive!)
3. Verify format: "SheetName!A1:D10"

Common Fixes:
â€¢ "Sheet1" not "sheet1" (case matters!)
â€¢ Include sheet name: "Data!A1:D10" not just "A1:D10"
â€¢ Check sheet wasn't deleted/renamed

Try semantic ranges: {"semantic":{"sheet":"Sales","column":"Total"}}`,

        PERMISSION_DENIED: `ğŸ”’ PERMISSION_DENIED - Authentication or Access Issue

Recovery Steps:
1. Check auth: sheets_auth action="status"
2. Re-authenticate: sheets_auth action="login"
3. Complete OAuth in browser
4. Retry operation

Access Check:
â€¢ Verify spreadsheet is shared with your account
â€¢ sheets_collaborate action="share_list" to see current access
â€¢ Request owner to share if needed

OAuth Scopes Needed:
https://www.googleapis.com/auth/spreadsheets`,

        INVALID_RANGE: `ğŸ“ INVALID_RANGE - Range Format Incorrect

Valid Formats:
âœ… "A1:D10"
âœ… "Sheet1!A1:D10"
âœ… "Sheet1!A:A" (entire column)
âœ… "Sheet1!1:1" (entire row)

Invalid Formats:
âŒ "A1-D10" (use : not -)
âŒ "A1..D10"
âŒ "SheetName A1:D10" (missing !)

Alternative: Use semantic ranges
{"semantic":{"sheet":"Data","column":"Revenue","includeHeader":false}}`,

        RATE_LIMIT_EXCEEDED: `ğŸš¦ RATE_LIMIT_EXCEEDED - Too Many Requests

Built-in Circuit Breaker Active:
â€¢ Automatic exponential backoff
â€¢ Request spacing (1-2 seconds)
â€¢ Auto-retry with delays

Your Action:
â€¢ Wait 10 seconds
â€¢ Use batch operations next time
â€¢ Let circuit breaker handle retries

Prevention: Batch operations reduce rate limit usage by 80%`,

        AUTH_EXPIRED: `ğŸ”‘ AUTH_EXPIRED - Token Expired

Auto-Recovery (Usually Works):
â€¢ Server auto-refreshes tokens
â€¢ Just retry your operation
â€¢ Token refresh happens automatically

Manual Recovery:
1. sheets_auth action="logout"
2. sheets_auth action="login"
3. Complete OAuth flow
4. Retry operation

Token Details:
â€¢ Expire after 1 hour
â€¢ Auto-refresh when possible
â€¢ Encrypted storage: GOOGLE_TOKEN_STORE_PATH`,

        NOT_FOUND: `ğŸ” NOT_FOUND - Spreadsheet Doesn't Exist

Verify ID:
â€¢ Format: 44 chars, alphanumeric plus - and _
â€¢ Get from URL: docs.google.com/spreadsheets/d/{ID}/...
â€¢ Check for typos

Find Spreadsheets:
1. List all: sheets_core action="list"
2. Create new: sheets_core action="create" title="My Sheet"

Common Issues:
â€¢ Spreadsheet deleted
â€¢ Wrong ID copied
â€¢ No access permission`,
      };

      const recovery =
        recoveryGuide[errorCode] ||
        `ğŸ”§ ${errorCode} Recovery

Tool: ${toolName || 'unknown'}
Message: ${errorMessage || 'No message provided'}
Context: ${context || 'No context provided'}

General Recovery:
1. Check tool description for correct format (see Quick Examples)
2. Verify spreadsheet ID and permissions
3. Check auth: sheets_auth action="status"
4. Review history: sheets_history
5. Try dry-run: {"safety":{"dryRun":true}}

Common Fixes:
â€¢ Auth: sheets_auth action="login"
â€¢ Quota: Wait 60s, use batch_read/batch_write
â€¢ Range: Verify with sheets_core action="get"
â€¢ Format: See tool description Quick Examples

Still Stuck?
â€¢ Logs: ~/Library/Logs/Claude/mcp*.log
â€¢ Version: node dist/cli.js --version
â€¢ Restart: Quit Claude Desktop (Cmd+Q), wait 5s, relaunch`;

      return {
        messages: [
          {
            role: 'user' as const,
            content: {
              type: 'text' as const,
              text: recovery,
            },
          },
        ],
      };
    }
  );

  // Performance Troubleshooting Prompt
  server.registerPrompt(
    'troubleshoot_performance',
    {
      description: 'âš¡ Diagnose and fix slow spreadsheet operations',
      argsSchema: TroubleshootPerformancePromptArgsSchema,
    },
    async (args: Record<string, unknown>) => {
      const spreadsheetId = args['spreadsheetId'] as string;
      const operation = (args['operation'] as string) || 'unknown';
      const responseTime = (args['responseTime'] as number) || 0;

      return {
        messages: [
          {
            role: 'user' as const,
            content: {
              type: 'text' as const,
              text: `âš¡ Performance Troubleshooting for ${spreadsheetId}

Operation: ${operation}
${responseTime > 0 ? `Response Time: ${responseTime}ms` : ''}

Common Performance Issues:

1. **Large Range Reads** (>10K cells)
   â€¢ Problem: Reading entire sheets instead of specific ranges
   â€¢ Fix: Use precise ranges like "A1:D100" instead of "A:Z"
   â€¢ Tool: sheets_data with exact range
   â€¢ Improvement: 80-90% faster

2. **Multiple Individual Operations**
   â€¢ Problem: 50 separate read calls instead of 1 batch
   â€¢ Fix: Use batch_read with multiple ranges
   â€¢ Tool: sheets_data action="batch_read" ranges=["A1:B10","D1:E10"]
   â€¢ Improvement: Saves 80% API quota, 3-5x faster

3. **Formula Recalculation**
   â€¢ Problem: Complex formulas with circular references
   â€¢ Fix: Use optimize_formulas prompt
   â€¢ Check: sheets_analyze action="analyze_formulas"
   â€¢ Improvement: 50-70% faster calculations

4. **Network Latency**
   â€¢ Problem: Too many round trips to Google API
   â€¢ Fix: Bundle operations in sheets_transaction
   â€¢ Improvement: Single API call instead of N calls

5. **Unoptimized Queries**
   â€¢ Problem: Reading full sheet to find one value
   â€¢ Fix: Use sheets_data action="find_replace" with criteria
   â€¢ Improvement: 95% faster than scanning

Diagnostic Steps:

1. Check range size:
   â€¢ sheets_core action="get" â†’ See total rows/columns
   â€¢ If >10K cells, reduce range

2. Enable profiling:
   â€¢ Add timing: const start = Date.now()
   â€¢ Measure each operation
   â€¢ Identify slowest step

3. Review recent operations:
   â€¢ sheets_history action="list" limit=10
   â€¢ Look for repeated calls

4. Analyze data structure:
   â€¢ sheets_analyze action="analyze_performance"
   â€¢ Get optimization suggestions

Quick Fixes by Operation Type:

â€¢ sheets_data read â†’ Use batch_read, exact ranges
â€¢ sheets_format â†’ Batch in sheets_transaction
â€¢ sheets_analyze â†’ Limit to <10K cells
â€¢ sheets_visualize â†’ Reduce source range size
â€¢ sheets_visualize â†’ Limit data points to <1000

Apply fixes and retest!`,
            },
          },
        ],
      };
    }
  );

  // Data Quality Fix Prompt
  server.registerPrompt(
    'fix_data_quality',
    {
      description: 'ğŸ” Identify and fix data quality issues',
      argsSchema: FixDataQualityPromptArgsSchema,
    },
    async (args: Record<string, unknown>) => {
      const spreadsheetId = args['spreadsheetId'] as string;
      const range = args['range'] as string;
      const issues = (args['issues'] as string) || 'auto-detect';

      return {
        messages: [
          {
            role: 'user' as const,
            content: {
              type: 'text' as const,
              text: `ğŸ” Data Quality Analysis for ${spreadsheetId}
Range: ${range}
${issues !== 'auto-detect' ? `Known Issues: ${issues}` : ''}

Step 1: Detect Issues
Run: sheets_analyze action="analyze_data" spreadsheetId="${spreadsheetId}" range="${range}"

Common Data Quality Problems:

1. **Empty Cells in Required Columns**
   â€¢ Detection: Check for null/empty values
   â€¢ Fix: sheets_data action="find_replace" find="" â†’ Fill or remove rows
   â€¢ Prevention: Add validation rules

2. **Duplicate Headers**
   â€¢ Detection: Count unique values in row 1
   â€¢ Fix: sheets_core action="update_sheet" â†’ Rename duplicates
   â€¢ Prevention: Validate on import

3. **Inconsistent Formats**
   â€¢ Detection: Mixed date formats, number formats
   â€¢ Fix: sheets_format action="set_number_format" format="YYYY-MM-DD"
   â€¢ Prevention: Apply format before data entry

4. **Invalid Values**
   â€¢ Detection: Negative ages, future dates, out-of-range numbers
   â€¢ Fix: sheets_data action="find_replace" with valid values
   â€¢ Prevention: sheets_format action="set_data_validation"

5. **Extra Whitespace**
   â€¢ Detection: Leading/trailing spaces
   â€¢ Fix: Use TRIM formula or sheets_data action="find_replace"
   â€¢ Prevention: Input validation

Cleanup Workflow:

1. Analyze:
   sheets_analyze action="analyze_data" range="${range}"

2. Fix empty cells:
   â€¢ Delete: sheets_dimensions action="delete_rows"
   â€¢ Fill: sheets_data action="write" with default values

3. Standardize formats:
   â€¢ Dates: sheets_format format="yyyy-mm-dd"
   â€¢ Currency: sheets_format format="$#,##0.00"
   â€¢ Percentages: sheets_format format="0.00%"

4. Remove duplicates:
   â€¢ Find: sheets_data action="find_replace"
   â€¢ Mark or delete duplicates

5. Add validation:
   â€¢ sheets_format action="set_data_validation" type="LIST"
   â€¢ Prevent future bad data

6. Verify:
   â€¢ Re-run sheets_analyze
   â€¢ Check quality score improved

After cleanup, consider:
â€¢ Create snapshot: sheets_collaborate action="version_create_snapshot"
â€¢ Document changes: sheets_collaborate action="comment_add"`,
            },
          },
        ],
      };
    }
  );

  // Formula Optimization Prompt
  server.registerPrompt(
    'optimize_formulas',
    {
      description: 'ğŸ“Š Optimize slow or inefficient formulas',
      argsSchema: OptimizeFormulasPromptArgsSchema,
    },
    async (args: Record<string, unknown>) => {
      const spreadsheetId = args['spreadsheetId'] as string;
      const range = (args['range'] as string) || 'entire sheet';

      return {
        messages: [
          {
            role: 'user' as const,
            content: {
              type: 'text' as const,
              text: `ğŸ“Š Formula Optimization for ${spreadsheetId}
${range !== 'entire sheet' ? `Range: ${range}` : ''}

Step 1: Audit Formulas
Run: sheets_analyze action="analyze_formulas" spreadsheetId="${spreadsheetId}"

Common Formula Performance Issues:

1. **VLOOKUP** (Slow for large datasets)
   â€¢ Problem: O(n) lookup, scans entire column
   â€¢ Fix: Replace with INDEX/MATCH
   â€¢ Before: =VLOOKUP(A2,Data!A:D,3,FALSE)
   â€¢ After: =INDEX(Data!C:C,MATCH(A2,Data!A:A,0))
   â€¢ Improvement: 60% faster

2. **Array Formulas** (Resource intensive)
   â€¢ Problem: Recalculates entire array on every change
   â€¢ Fix: Split into individual cell formulas
   â€¢ Or: Use FILTER() with specific criteria
   â€¢ Improvement: 70% faster

3. **Volatile Functions** (Recalculate constantly)
   â€¢ Problem: NOW(), RAND(), INDIRECT() recalc on every edit
   â€¢ Fix: Replace with static values or manual triggers
   â€¢ NOW() â†’ Use timestamp in cell, update manually
   â€¢ INDIRECT() â†’ Use direct cell references
   â€¢ Improvement: 80% less recalculation

4. **Circular References**
   â€¢ Problem: Formulas referencing themselves
   â€¢ Detection: sheets_analyze shows circular_refs
   â€¢ Fix: Break cycle by moving calculation to different cell
   â€¢ Improvement: Prevents infinite loops

5. **Nested IFs** (Hard to read and slow)
   â€¢ Problem: =IF(A1>10,IF(A1>20,"High","Medium"),"Low")
   â€¢ Fix: Use IFS() or lookup table
   â€¢ After: =IFS(A1>20,"High",A1>10,"Medium",TRUE,"Low")
   â€¢ Improvement: More readable, 30% faster

Optimization Workflow:

1. Find slow formulas:
   â€¢ sheets_analyze action="analyze_formulas"
   â€¢ Look for: VLOOKUP, array formulas, volatile functions

2. Test performance:
   â€¢ Time recalculation (Ctrl+Alt+Shift+F9 in Sheets)
   â€¢ Identify slowest formulas

3. Replace VLOOKUP:
   â€¢ Find all: sheets_data action="find_replace" find="VLOOKUP"
   â€¢ Replace manually with INDEX/MATCH pattern

4. Simplify array formulas:
   â€¢ Convert to individual formulas
   â€¢ Or use more efficient array operations

5. Remove volatile functions:
   â€¢ Replace NOW() with manual timestamp
   â€¢ Replace INDIRECT() with direct references

6. Verify improvements:
   â€¢ Re-run formula audit
   â€¢ Test recalculation speed

Formula Best Practices:

â€¢ Use named ranges (easier to read and maintain)
â€¢ Avoid full column references (A:A) when possible
â€¢ Cache lookup results instead of repeated calculations
â€¢ Use FILTER() instead of complex IF arrays
â€¢ Break complex formulas into intermediate cells

After optimization:
â€¢ Document changes in comments
â€¢ Create version snapshot
â€¢ Monitor performance over time`,
            },
          },
        ],
      };
    }
  );

  // Bulk Import Workflow Prompt
  server.registerPrompt(
    'bulk_import_data',
    {
      description: 'ğŸ“¥ Efficiently import large datasets',
      argsSchema: BulkImportDataPromptArgsSchema,
    },
    async (args: Record<string, unknown>) => {
      const spreadsheetId = args['spreadsheetId'] as string;
      const dataSize = (args['dataSize'] as number) || 0;
      const dataSource = (args['dataSource'] as string) || 'external source';

      return {
        messages: [
          {
            role: 'user' as const,
            content: {
              type: 'text' as const,
              text: `ğŸ“¥ Bulk Data Import Workflow for ${spreadsheetId}
Source: ${dataSource}
${dataSize > 0 ? `Estimated Rows: ${dataSize}` : ''}

Optimal Import Strategy:

${
  dataSize > 10000
    ? `âš ï¸ LARGE DATASET (${dataSize} rows)
Use chunked imports with transactions`
    : ''
}

Step 1: Prepare Target Sheet
1. Create or clear target sheet:
   sheets_core action="add_sheet" title="Import_${new Date().toISOString().split('T')[0]}"

2. Setup structure:
   â€¢ Headers: sheets_data action="write" range="A1:Z1" values=[["Col1","Col2",...]]
   â€¢ Format headers: sheets_format range="A1:Z1" bold=true backgroundColor="#4285F4"
   â€¢ Freeze: sheets_dimensions action="freeze_rows" count=1

Step 2: Validate Source Data
1. Check data quality before import
2. Remove: Empty rows, invalid characters, duplicates
3. Standardize: Date formats, number formats, text encoding

Step 3: Import Data (Choose Strategy)

**Strategy A: Small Dataset (<1000 rows)**
â€¢ Single batch write:
  sheets_data action="batch_write" ranges=["A2:Z1001"] values=[...]

**Strategy B: Medium Dataset (1K-10K rows)**
â€¢ Transaction with chunks:
  sheets_transaction action="begin"
  For each chunk of 1000 rows:
    sheets_transaction action="add_operation" operation=write
  sheets_transaction action="commit"

**Strategy C: Large Dataset (>10K rows)**
â€¢ Multiple transactions:
  For every 5000 rows:
    Begin transaction â†’ Write 5 chunks of 1000 â†’ Commit
    Wait 2 seconds between transactions

Step 4: Post-Import Processing

1. Auto-resize columns:
   sheets_dimensions action="auto_resize" dimension="COLUMNS"

2. Apply formatting:
   â€¢ Currency columns: sheets_format format="$#,##0.00"
   â€¢ Date columns: sheets_format format="yyyy-mm-dd"
   â€¢ Conditional formatting: sheets_format for visual cues

3. Add validation rules:
   â€¢ Dropdowns: sheets_format action="set_data_validation" type="LIST"
   â€¢ Range validation: For numeric columns

4. Create summary:
   â€¢ Row count, column count
   â€¢ Add to first sheet or separate "Summary" sheet

Step 5: Verification

1. Data quality check:
   sheets_analyze action="analyze_data" range="A1:Z${dataSize || 10000}"

2. Spot check:
   â€¢ First 10 rows: sheets_data range="A2:Z11"
   â€¢ Last 10 rows: Check end of data
   â€¢ Random sample: Middle rows

3. Create checkpoint:
   sheets_collaborate action="version_create_snapshot" description="After ${dataSource} import"

Performance Tips:

â€¢ Batch size: 1000 rows optimal for balance of speed/reliability
â€¢ Use batch_write not individual writes (80% faster)
â€¢ Wait 2s between large transactions (avoid rate limits)
â€¢ Format after data import (faster than formatting during)
â€¢ Create indexes with named ranges for quick access

Error Recovery:

â€¢ If import fails mid-way:
  1. sheets_history action="list" - Find last successful operation
  2. sheets_transaction action="rollback" - Undo partial import
  3. Resume from last checkpoint

â€¢ If data quality issues found:
  Use fix_data_quality prompt for cleanup

Import complete! âœ…`,
            },
          },
        ],
      };
    }
  );

  // ===Safety Workflow Prompts ===

  server.registerPrompt(
    'safe_operation',
    {
      description:
        'ğŸ›¡ï¸ Execute destructive operations safely with dry-run â†’ confirm â†’ execute workflow',
      argsSchema: SafeOperationPromptArgsSchema,
    },
    async (args: Record<string, unknown>) => {
      const operationType = args['operationType'] as string;
      const affectedRange = (args['affectedRange'] as string) || 'auto-detect';

      return {
        messages: [
          {
            role: 'user' as const,
            content: {
              type: 'text' as const,
              text: `ğŸ›¡ï¸ Safe ${operationType} Workflow
Spreadsheet: ${args['spreadsheetId']}
${affectedRange !== 'auto-detect' ? `Range: ${affectedRange}` : ''}

âš ï¸ CRITICAL: ${operationType} operations are PERMANENT. Follow this workflow:

Phase 1: DRY-RUN (Preview)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Preview what will happen:      â”‚
â”‚    {"safety":{"dryRun":true}}     â”‚
â”‚                                    â”‚
â”‚ 2. Review the preview output      â”‚
â”‚ 3. Verify affected ranges         â”‚
â”‚ 4. Check estimated impact         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Phase 2: IMPACT ANALYSIS
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Check dependencies:            â”‚
â”‚    sheets_quality action="analyze_impact" â”‚
â”‚                                    â”‚
â”‚ 2. Find affected formulas         â”‚
â”‚ 3. List dependent charts          â”‚
â”‚ 4. Identify broken references     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Phase 3: USER CONFIRMATION ${affectedRange.includes(':') && affectedRange.split(':').length > 1 ? '(REQUIRED)' : ''}
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MUST use sheets_confirm for:      â”‚
â”‚ â€¢ ${operationType === 'delete' ? 'Deleting >10 rows/columns' : ''}${operationType === 'bulk_update' ? 'Updating >100 cells' : ''}${operationType === 'format' ? 'Formatting >100 cells' : ''}${operationType === 'formula' ? 'Changing complex formulas' : ''}  â”‚
â”‚                                    â”‚
â”‚ Build confirmation plan:          â”‚
â”‚ {                                 â”‚
â”‚   "action": "request",            â”‚
â”‚   "plan": {                       â”‚
â”‚     "title": "${operationType} operation",â”‚
â”‚     "steps": [                    â”‚
â”‚       {                          â”‚
â”‚         "description": "...",    â”‚
â”‚         "risk": "high",          â”‚
â”‚         "isDestructive": true,   â”‚
â”‚         "canUndo": true          â”‚
â”‚       }                          â”‚
â”‚     ]                            â”‚
â”‚   }                              â”‚
â”‚ }                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Phase 4: SNAPSHOT (Undo Capability)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Create restore point:             â”‚
â”‚ {"safety":{"createSnapshot":true}}â”‚
â”‚                                    â”‚
â”‚ OR use sheets_collaborate:           â”‚
â”‚ sheets_collaborate action="version_create_snapshot"â”‚
â”‚ description="Before ${operationType}" â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Phase 5: EXECUTE SAFELY
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Remove dryRun flag             â”‚
â”‚ 2. Keep createSnapshot:true       â”‚
â”‚ 3. Execute operation              â”‚
â”‚ 4. Verify results immediately     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Phase 6: VERIFY
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Run sheets_analyze to verify  â”‚
â”‚ 2. Spot-check affected ranges     â”‚
â”‚ 3. Test dependent formulas        â”‚
â”‚ 4. Confirm no broken references   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

UNDO if needed:
â€¢ sheets_history action="undo"
â€¢ sheets_collaborate action="version_restore_revision" revisionId="..."
â€¢ sheets_transaction action="rollback" (if in transaction)

Remember: DRY-RUN â†’ IMPACT â†’ CONFIRM â†’ SNAPSHOT â†’ EXECUTE â†’ VERIFY`,
            },
          },
        ],
      };
    }
  );

  server.registerPrompt(
    'bulk_import',
    {
      description: 'ğŸ“¦ Import large datasets efficiently using transactions (80% quota savings)',
      argsSchema: BulkImportPromptArgsSchema,
    },
    async (args: Record<string, unknown>) => {
      const rowCount = (args['rowCount'] as number) || 0;
      const targetSheet = (args['targetSheet'] as string) || 'new sheet';

      return {
        messages: [
          {
            role: 'user' as const,
            content: {
              type: 'text' as const,
              text: `ğŸ“¦ Bulk Import Workflow
Spreadsheet: ${args['spreadsheetId']}
Data: ${args['dataDescription']}
Target: ${targetSheet}
${rowCount > 0 ? `Rows: ~${rowCount}` : ''}

ğŸš€ TRANSACTION WORKFLOW (Required for efficiency):

Step 1: BEGIN Transaction
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ sheets_transaction action="begin" â”‚
â”‚ spreadsheetId="${args['spreadsheetId']}"   â”‚
â”‚ autoRollback=true                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â†’ Returns: transactionId="tx_..."

Step 2: QUEUE Operations
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ For each data chunk (1000 rows):  â”‚
â”‚                                    â”‚
â”‚ sheets_transaction action="queue" â”‚
â”‚ transactionId="tx_..."            â”‚
â”‚ operation={                        â”‚
â”‚   tool: "sheets_data",          â”‚
â”‚   action: "write",                â”‚
â”‚   params: {                       â”‚
â”‚     range: "A2:Z1001",           â”‚
â”‚     values: [[...]]              â”‚
â”‚   }                              â”‚
â”‚ }                                 â”‚
â”‚                                    â”‚
â”‚ Repeat for each chunk...          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 3: COMMIT All Operations
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ sheets_transaction action="commit"â”‚
â”‚ transactionId="tx_..."            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â†’ Executes ALL operations in 1 API call!

Performance Benefits:
âœ… 1 API call instead of ${rowCount > 0 ? Math.ceil(rowCount / 1000) : 'N'} calls
âœ… 80-95% quota savings
âœ… 10x faster execution
âœ… Atomic execution (all-or-nothing)
âœ… Auto-rollback on failure

Optimal Strategy by Size:

${rowCount < 1000 ? 'ğŸ“˜ SMALL (<1000 rows): Single transaction, all data at once' : ''}
${rowCount >= 1000 && rowCount < 10000 ? 'ğŸ“— MEDIUM (1K-10K): Single transaction, chunked into 1000-row writes' : ''}
${rowCount >= 10000 ? 'ğŸ“• LARGE (>10K): Multiple transactions, 5000 rows each, 2s pause between' : ''}

Complete Example:
\`\`\`
# 1. Begin
sheets_transaction begin â†’ tx_123

# 2. Queue writes (repeat for each chunk)
sheets_transaction queue tx_123 operation=write range=A2:Z1001
sheets_transaction queue tx_123 operation=write range=A1002:Z2001
sheets_transaction queue tx_123 operation=write range=A2002:Z3001

# 3. Commit (1 API call executes all)
sheets_transaction commit tx_123
â†’ 3 operations, 1 API call, 66% quota saved!
\`\`\`

Error Recovery:
â€¢ If commit fails â†’ Auto-rollback (no partial writes)
â€¢ If need to abort â†’ sheets_transaction rollback tx_123
â€¢ Spreadsheet stays consistent (atomic guarantee)

After Import:
1. sheets_dimensions action="auto_resize" (columns)
2. sheets_format (apply formatting)
3. sheets_collaborate action="version_create_snapshot" (checkpoint)
4. sheets_analyze action="analyze_quality" (verify)

Transaction = Speed + Safety + Atomicity`,
            },
          },
        ],
      };
    }
  );

  server.registerPrompt(
    'undo_changes',
    {
      description: 'âª Undo recent changes using version history or operation history',
      argsSchema: UndoChangesPromptArgsSchema,
    },
    async (args: Record<string, unknown>) => {
      const changeDesc = (args['changeDescription'] as string) || 'recent changes';

      return {
        messages: [
          {
            role: 'user' as const,
            content: {
              type: 'text' as const,
              text: `âª Undo: ${changeDesc}
Spreadsheet: ${args['spreadsheetId']}

ğŸ” Step 1: Identify What to Undo

Option A: Recent Operations (Last 100 ops)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ sheets_history action="list"      â”‚
â”‚ spreadsheetId="${args['spreadsheetId']}"   â”‚
â”‚ limit=20                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â†’ Shows recent operations with IDs

Option B: Version History (Google's snapshots)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ sheets_collaborate action="version_list_revisions"â”‚
â”‚ spreadsheetId="${args['spreadsheetId']}"   â”‚
â”‚ limit=10                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â†’ Shows saved snapshots

âª Step 2: Choose Undo Method

Method 1: HISTORY ROLLBACK (Precise)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Best for: Specific operation undo  â”‚
â”‚                                    â”‚
â”‚ sheets_history action="undo"      â”‚
â”‚ spreadsheetId="${args['spreadsheetId']}"   â”‚
â”‚ operationId="op_12345"            â”‚
â”‚                                    â”‚
â”‚ OR revert to specific point:      â”‚
â”‚ sheets_history action="revert_to" â”‚
â”‚ operationId="op_12345"            â”‚
â”‚ (undoes everything after this)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Method 2: VERSION RESTORE (Full restore)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Best for: Major undo, "go back"   â”‚
â”‚                                    â”‚
â”‚ sheets_collaborate action="version_restore_revision"  â”‚
â”‚ spreadsheetId="${args['spreadsheetId']}"   â”‚
â”‚ revisionId="rev_abc123"           â”‚
â”‚                                    â”‚
â”‚ Restores ENTIRE spreadsheet to    â”‚
â”‚ that point in time                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Method 3: TRANSACTION ROLLBACK (In-progress)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Best for: Active transaction       â”‚
â”‚                                    â”‚
â”‚ sheets_transaction action="rollback"â”‚
â”‚ transactionId="tx_123"            â”‚
â”‚                                    â”‚
â”‚ Undoes uncommitted operations     â”‚
â”‚ (only works before commit)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ” Decision Tree:

Q: Is the change from the last few operations?
  âœ… Use sheets_history action="undo"

Q: Do you need to go back >100 operations?
  âœ… Use sheets_collaborate action="version_restore_revision"

Q: Is a transaction still in progress?
  âœ… Use sheets_transaction action="rollback"

Q: Want to undo specific cells only?
  âœ… Manually write old values back:
     1. Get old values from history/version
     2. sheets_data action="write" with old values

ğŸ“‹ Verification After Undo:

1. Check the change was undone:
   sheets_core action="get"
   sheets_data action="read" range="affected_range"

2. Verify no broken references:
   sheets_analyze action="analyze_formulas"

3. Check data quality:
   sheets_analyze action="analyze_quality"

âš ï¸ Important Notes:

â€¢ History: Keeps last 100 operations (~24 hours typical)
â€¢ Versions: Google saves automatically (~every 30 min when editing)
â€¢ Manual snapshots: Created with createSnapshot:true in safety params
â€¢ Transaction rollback: Only before commit

ğŸ›¡ï¸ Prevent Need for Undo:

ALWAYS use safety workflow for destructive ops:
1. {"safety":{"dryRun":true}} â†’ Preview
2. sheets_confirm â†’ User approval
3. {"safety":{"createSnapshot":true}} â†’ Backup
4. Execute â†’ With safety guards
5. Verify â†’ Check results

Then you'll always have an easy undo path!`,
            },
          },
        ],
      };
    }
  );

  // === CONFIRMATION GUIDE PROMPTS ===

  server.registerPrompt(
    'when_to_confirm',
    {
      description: 'ğŸ›¡ï¸ Learn when and how to request user confirmation before operations',
      argsSchema: {},
    },
    async () => {
      return {
        messages: [
          {
            role: 'user' as const,
            content: {
              type: 'text' as const,
              text: `ğŸ›¡ï¸ When to Request User Confirmation

This guide tells you EXACTLY when to use sheets_confirm.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ”´ ALWAYS CONFIRM (No exceptions):

1. DELETING SHEETS
   â€¢ Any sheets_core action="delete_sheet" call
   â€¢ Say: "This will permanently delete the sheet and all its data."

2. DELETING ROWS (>10)
   â€¢ sheets_dimensions action="delete_rows" with count > 10
   â€¢ Say: "I found {N} rows to delete. Want to see which ones first?"

3. DELETING COLUMNS (>3)
   â€¢ sheets_dimensions action="delete_columns" with count > 3
   â€¢ Say: "Deleting {N} columns may affect formulas. Proceed?"

4. CLEARING DATA (>100 cells)
   â€¢ sheets_data action="clear" on large ranges
   â€¢ Say: "This will erase {N} cells of data. Continue?"

5. LARGE WRITES (>500 cells)
   â€¢ sheets_data action="write" with >500 cells
   â€¢ Say: "I'll update {N} cells. Create a backup first?"

6. MULTI-STEP OPERATIONS (3+ steps)
   â€¢ When your plan has 3 or more operations
   â€¢ Use sheets_confirm to show the plan

7. SHARING/PERMISSIONS
   â€¢ Any sheets_collaborate call
   â€¢ Say: "This will give {email} access to your data."

8. ANYTHING USER DIDN'T EXPLICITLY REQUEST
   â€¢ If you're doing something as a side effect
   â€¢ Always ask first

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸŸ¡ SUGGEST CONFIRMATION (Offer, don't require):

â€¢ 50-500 cell modifications
â€¢ Formatting large ranges
â€¢ Adding formulas to existing data
â€¢ Sorting/filtering operations
â€¢ Import operations

How to offer: "I'll update {N} cells. Want me to show a preview first?"

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âœ… NO CONFIRMATION NEEDED:

â€¢ All read operations (read, get, list, find)
â€¢ Single cell updates user explicitly asked for
â€¢ Small writes (<50 cells) user requested
â€¢ Analysis operations
â€¢ Getting statistics

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“‹ HOW TO USE sheets_confirm:

Step 1: Build a plan
\`\`\`json
{
  "action": "request",
  "plan": {
    "title": "Delete Empty Rows",
    "description": "Remove 47 rows with no data",
    "steps": [
      {
        "stepNumber": 1,
        "description": "Delete 47 empty rows",
        "tool": "sheets_dimensions",
        "action": "delete_rows",
        "risk": "high",
        "isDestructive": true,
        "canUndo": true
      }
    ],
    "willCreateSnapshot": true,
    "additionalWarnings": ["Cannot be undone without snapshot"]
  }
}
\`\`\`

Step 2: Call sheets_confirm

Step 3: Check response
â€¢ If approved â†’ Execute the plan
â€¢ If declined â†’ Abort and explain what was avoided
â€¢ If modified â†’ Adjust plan per user feedback

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ’¡ CONVERSATIONAL ALTERNATIVES:

Instead of formal sheets_confirm, you can also ask naturally:

â€¢ "Before I delete these 15 rows, want to see which ones?"
â€¢ "This will clear 200 cells. Should I create a backup first?"
â€¢ "I found 3 duplicates. Remove them?"

But for ANYTHING destructive or large, sheets_confirm is preferred
because it shows a proper UI and creates an audit trail.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ¯ GOLDEN RULES:

1. Deletion = ALWAYS confirm
2. >100 cells = ALWAYS confirm
3. Sharing = ALWAYS confirm
4. Multi-step = ALWAYS show plan
5. Small explicit requests = No confirmation
6. When uncertain = ASK
7. Offer snapshots for destructive ops
8. Offer dryRun when user seems unsure`,
            },
          },
        ],
      };
    }
  );

  server.registerPrompt(
    'confirmation_examples',
    {
      description: 'ğŸ“ Examples of good vs bad confirmation behavior',
      argsSchema: {},
    },
    async () => {
      return {
        messages: [
          {
            role: 'user' as const,
            content: {
              type: 'text' as const,
              text: `ğŸ“ Confirmation Examples: Good vs Bad

Learn from these examples of proper confirmation behavior.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

EXAMPLE 1: Delete rows with empty status

User: "Delete all rows where status is empty"

âŒ BAD (Don't do this):
"Done! I deleted 23 rows."

âœ… GOOD:
"I found 23 rows with empty status. Before I delete them:
1. Want to see which rows they are?
2. I'll create a snapshot so you can undo if needed.

Ready to proceed?"

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

EXAMPLE 2: Clear a column

User: "Clear column D"

âŒ BAD:
"Cleared column D."

âœ… GOOD:
"Column D has 847 cells with data. Clearing them all will:
â€¢ Erase all values in D2:D848
â€¢ Break any formulas referencing this column

Should I:
a) Show you what's in column D first?
b) Create a snapshot then clear?
c) Clear just empty rows?"

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

EXAMPLE 3: Simple cell update

User: "Change cell A1 to 'Hello'"

âŒ BAD (Over-confirming):
"Are you absolutely sure you want to change A1? This will 
overwrite the existing value. Please confirm..."

âœ… GOOD:
"Done! Changed A1 to 'Hello'."

(No confirmation needed for small, explicit requests)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

EXAMPLE 4: Create a CRM (multi-step)

User: "Set up a CRM for me"

âŒ BAD:
"Creating CRM... done! I made 6 sheets and added formulas."

âœ… GOOD:
"I'll create a CRM with:
â€¢ ğŸ“Š Dashboard - Overview and metrics
â€¢ ğŸ‘¥ Contacts - Your contact list
â€¢ ğŸ¢ Companies - Business accounts
â€¢ ğŸ’° Deals - Sales pipeline
â€¢ ğŸ“ Activities - Task tracking
â€¢ âš™ï¸ Settings - Dropdown values

This involves about 15 operations. Here's my plan:
[Shows plan via sheets_confirm]

Ready to create it?"

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

EXAMPLE 5: Share spreadsheet

User: "Share this with john@example.com"

âŒ BAD:
"Shared with john@example.com as editor."

âœ… GOOD:
"I'll share with john@example.com. What permission level?
â€¢ ğŸ‘ï¸ Viewer - Can only view
â€¢ ğŸ’¬ Commenter - Can view and comment
â€¢ âœï¸ Editor - Can make changes

Also, should I send them a notification email?"

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

EXAMPLE 6: User says "just do it"

User: "Just format all the headers, don't ask me"

âœ… CORRECT BEHAVIOR:
"Got it! Formatting headers now..."
(Respect user's preference for less confirmation)

But then track this preference for future operations.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

KEY TAKEAWAYS:

1. Big operations â†’ Always confirm with details
2. Small explicit requests â†’ Just do it
3. Destructive operations â†’ Offer snapshot + confirm
4. Multi-step â†’ Show the plan first
5. Respect "just do it" preferences
6. When in doubt â†’ Ask nicely`,
            },
          },
        ],
      };
    }
  );

  // === ADVANCED WORKFLOW PROMPTS ===

  server.registerPrompt(
    'advanced_data_migration',
    {
      description:
        'ğŸš€ Advanced multi-sheet, multi-spreadsheet data migration with transformation and validation',
      argsSchema: AdvancedDataMigrationPromptArgsSchema,
    },
    async (args: Record<string, unknown>) => {
      const migrationType = (args['migrationType'] as string) || 'full';
      const hasTransformations = Boolean(args['transformations']);

      return {
        messages: [
          {
            role: 'user' as const,
            content: {
              type: 'text' as const,
              text: `ğŸš€ Advanced Data Migration Workflow

Source: ${args['sourceSpreadsheetId']}
Target: ${args['targetSpreadsheetId']}
Type: ${migrationType}
${hasTransformations ? `Transformations: ${args['transformations']}` : ''}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“‹ PHASE 1: DISCOVERY & PLANNING

1. Analyze Source Structure:
   sheets_core action="list_sheets" â†’ Get all sheets
   For each sheet:
     sheets_data action="read" range="{sheet}!A1:Z1" â†’ Get headers
     sheets_analyze action="analyze_structure" â†’ Understand data types
     sheets_analyze action="analyze_quality" â†’ Check quality issues

2. Analyze Target Structure:
   sheets_core action="get" spreadsheetId=target
   Identify: Matching sheets, conflicts, missing sheets

3. Build Migration Plan:
   â€¢ Sheet mapping (source â†’ target)
   â€¢ Column mapping (handle renames/reordering)
   â€¢ Data type conversions needed
   â€¢ Validation rules to preserve
   â€¢ Formulas to update (cell references)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âš™ï¸  PHASE 2: PRE-MIGRATION VALIDATION

1. Compatibility Check:
   â€¢ Verify target has capacity (row/column limits)
   â€¢ Check for naming conflicts
   â€¢ Validate data type compatibility
   â€¢ Identify potential data loss scenarios

2. Impact Analysis:
   sheets_quality action="analyze_impact" operation="migrate"
   â€¢ Find dependent sheets/formulas
   â€¢ Identify broken references after migration
   â€¢ Calculate migration complexity

3. Create Safety Net:
   sheets_collaborate action="version_create_snapshot" spreadsheetId=target
   description="Before ${migrationType} migration from ${args['sourceSpreadsheetId']}"

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ”„ PHASE 3: DATA MIGRATION (Choose Strategy)

${
  migrationType === 'full'
    ? `
**FULL MIGRATION Strategy:**

For each source sheet:

  Step 1: Prepare Target Sheet
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Create or clear target sheet:     â”‚
  â”‚ sheets_core action="add_sheet"         â”‚
  â”‚   OR                              â”‚
  â”‚ sheets_data action="clear"      â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  Step 2: Migrate Data with Transaction
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ sheets_transaction action="begin" â”‚
  â”‚                                    â”‚
  â”‚ Queue operations:                  â”‚
  â”‚ 1. Write headers (transformed)    â”‚
  â”‚ 2. Write data in 1000-row chunks  â”‚
  â”‚ 3. Copy formatting rules          â”‚
  â”‚ 4. Recreate data validation       â”‚
  â”‚ 5. Update formulas (refs)         â”‚
  â”‚                                    â”‚
  â”‚ sheets_transaction action="commit"â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  Step 3: Verify Migration
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ â€¢ Row count match                  â”‚
  â”‚ â€¢ Column count match              â”‚
  â”‚ â€¢ Spot-check sample data          â”‚
  â”‚ â€¢ Verify formulas work            â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
`
    : migrationType === 'incremental'
      ? `
**INCREMENTAL MIGRATION Strategy:**

Migrate only NEW or CHANGED data:

Step 1: Find Delta
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Identify changes since last sync: â”‚
â”‚ â€¢ Compare row counts              â”‚
â”‚ â€¢ Check modification timestamps   â”‚
â”‚ â€¢ Hash data for change detection  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 2: Sync Changes
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ For NEW rows:                      â”‚
â”‚   sheets_data action="append"   â”‚
â”‚                                    â”‚
â”‚ For MODIFIED rows:                â”‚
â”‚   sheets_composite action="bulk_update"â”‚
â”‚   keyColumn="ID"                  â”‚
â”‚                                    â”‚
â”‚ For DELETED rows:                 â”‚
â”‚   sheets_dimensions action="delete_rows"â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
`
      : `
**SELECTIVE MIGRATION Strategy:**

Migrate specific ranges or conditions:

Step 1: Define Selection Criteria
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â€¢ Specific ranges                  â”‚
â”‚ â€¢ Filter conditions               â”‚
â”‚ â€¢ Date ranges                     â”‚
â”‚ â€¢ Data quality thresholds         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 2: Extract and Transform
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ For each selection:               â”‚
â”‚   sheets_data action="read"     â”‚
â”‚   Apply transformations           â”‚
â”‚   Validate data                   â”‚
â”‚   sheets_data action="write" targetâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
`
}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ§ª PHASE 4: POST-MIGRATION VALIDATION

1. Data Integrity Checks:
   âœ“ Row counts match (source vs target)
   âœ“ No data loss (spot-check samples)
   âœ“ Formulas working (no #REF! errors)
   âœ“ Data types preserved
   âœ“ Formatting preserved (if needed)

2. Quality Analysis:
   sheets_analyze action="analyze_quality" spreadsheetId=target
   â€¢ Check for: empty cells, duplicates, outliers
   â€¢ Compare quality scores: source vs target

3. Formula Verification:
   sheets_analyze action="analyze_formulas"
   â€¢ Verify no broken references
   â€¢ Check formula complexity unchanged
   â€¢ Test key calculations

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“Š PHASE 5: RECONCILIATION & REPORTING

1. Generate Migration Report:
   {
     "summary": {
       "sheetsProcessed": N,
       "rowsMigrated": N,
       "formulasUpdated": N,
       "dataQuality": "PASS/FAIL",
       "duration": "MM:SS"
     },
     "issues": [
       {"type": "WARNING", "sheet": "Sheet1", "description": "..."}
     ],
     "recommendations": [...]
   }

2. Create Verification Sheet:
   sheets_core action="add_sheet" title="Migration_Verification"
   Add summary table with:
   â€¢ Sheet-by-sheet comparison
   â€¢ Row count deltas
   â€¢ Quality scores
   â€¢ Issues found

3. Final Snapshot:
   sheets_collaborate action="version_create_snapshot"
   description="After ${migrationType} migration - SUCCESS"

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ¯ SUCCESS CRITERIA

âœ… All sheets migrated without data loss
âœ… Formula references updated correctly
âœ… Data quality maintained or improved
âœ… No broken validations or formatting
âœ… Verification report generated
âœ… Snapshots created for rollback

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âš ï¸  ROLLBACK PROCEDURE (If Issues Found)

1. sheets_collaborate action="version_restore_revision" revisionId="pre-migration"
2. Review migration report for root cause
3. Fix issues in migration logic
4. Re-run migration with corrections

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ’¡ PRO TIPS

â€¢ Use transactions for atomicity (all-or-nothing)
â€¢ Migrate during low-usage hours
â€¢ Test migration on copy first
â€¢ Keep source spreadsheet until verified
â€¢ Document column mappings for future reference
â€¢ Monitor API quota usage during large migrations
â€¢ Use batch operations (80% faster than individual)

Ready to execute migration! ğŸš€`,
            },
          },
        ],
      };
    }
  );

  server.registerPrompt(
    'performance_audit',
    {
      description:
        'âš¡ Comprehensive spreadsheet performance audit with optimization recommendations',
      argsSchema: PerformanceAuditPromptArgsSchema,
    },
    async (args: Record<string, unknown>) => {
      const focusAreas = (args['focusAreas'] as string[]) || ['all'];

      return {
        messages: [
          {
            role: 'user' as const,
            content: {
              type: 'text' as const,
              text: `âš¡ Performance Audit for ${args['spreadsheetId']}
Focus: ${focusAreas.join(', ')}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ” PHASE 1: BASELINE ASSESSMENT

1. Spreadsheet Structure:
   sheets_core action="get"

   Analyze:
   â€¢ Total sheets: N
   â€¢ Total cells: rows Ã— columns Ã— sheets
   â€¢ File size estimate: (cells Ã— 100 bytes)
   â€¢ Sheets with >10K rows (performance risk)
   â€¢ Sheets with >26 columns (Z+) (complexity indicator)

2. Formula Complexity Analysis:
   sheets_analyze action="analyze_formulas"

   Identify:
   â€¢ Total formulas: N
   â€¢ Volatile functions: NOW(), RAND(), INDIRECT() (expensive!)
   â€¢ Array formulas: {...} (recalc intensive)
   â€¢ VLOOKUP usage: (suggest INDEX/MATCH)
   â€¢ Circular references: (performance killer)
   â€¢ Nested IF depth: >3 levels (hard to maintain)
   â€¢ External references: OtherSheet!A1 (cross-sheet dependencies)

3. Data Quality Check:
   sheets_analyze action="analyze_quality"

   Find:
   â€¢ Empty rows/columns: (wasted space)
   â€¢ Duplicate data: (use sheets_composite deduplicate)
   â€¢ Inconsistent data types: (causes formula errors)
   â€¢ Large text fields: >1000 chars (slow rendering)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“Š PHASE 2: PERFORMANCE BOTTLENECK DETECTION

**Formula Performance Issues:**

ğŸ”´ CRITICAL (Fix Immediately):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â€¢ Volatile functions in large ranges              â”‚
â”‚   Problem: NOW() in 10,000 cells = 10K recalcs   â”‚
â”‚   Fix: Replace with static timestamp             â”‚
â”‚                                                    â”‚
â”‚ â€¢ Circular references                             â”‚
â”‚   Problem: Infinite calculation loops            â”‚
â”‚   Fix: Break cycle by moving calc to new cell    â”‚
â”‚                                                    â”‚
â”‚ â€¢ Array formulas on full columns (A:A)           â”‚
â”‚   Problem: Evaluates all 1M rows                 â”‚
â”‚   Fix: Use specific range A1:A1000               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸŸ¡ HIGH PRIORITY (Fix Soon):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â€¢ VLOOKUP on large datasets                       â”‚
â”‚   Before: =VLOOKUP(A2,Data!A:D,3,FALSE)         â”‚
â”‚   After:  =INDEX(Data!C:C,MATCH(A2,Data!A:A,0)) â”‚
â”‚   Gain: 60% faster                               â”‚
â”‚                                                    â”‚
â”‚ â€¢ Nested IF statements (>3 levels)               â”‚
â”‚   Before: =IF(A1>10,IF(A1>20,"H","M"),"L")      â”‚
â”‚   After:  =IFS(A1>20,"H",A1>10,"M",TRUE,"L")    â”‚
â”‚   Gain: More readable, 30% faster               â”‚
â”‚                                                    â”‚
â”‚ â€¢ INDIRECT for dynamic references                â”‚
â”‚   Problem: Recalculates on every change         â”‚
â”‚   Fix: Use direct cell references or named rangesâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

**Data Structure Issues:**

ğŸ”´ CRITICAL:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â€¢ Sheets with >100K cells                         â”‚
â”‚   Solution: Split into multiple sheets           â”‚
â”‚             Use pivot tables for summaries       â”‚
â”‚                                                    â”‚
â”‚ â€¢ Excessive empty rows (trailing data)           â”‚
â”‚   Solution: sheets_dimensions action="delete_rows"â”‚
â”‚             Clean up data range                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âš™ï¸  PHASE 3: API USAGE OPTIMIZATION

Check Current Efficiency:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Resource: cache://stats                           â”‚
â”‚                                                    â”‚
â”‚ Current Stats:                                    â”‚
â”‚ â€¢ API calls: N                                    â”‚
â”‚ â€¢ Cache hit rate: X%                              â”‚
â”‚ â€¢ Efficiency gain: Y%                             â”‚
â”‚                                                    â”‚
â”‚ Target: >50% efficiency gain                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Optimization Recommendations:

1ï¸âƒ£  BATCHING (20-40% savings)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âŒ DON'T: Multiple individual reads                â”‚
â”‚    sheets_data action="read" range="A1:B10"     â”‚
â”‚    sheets_data action="read" range="D1:E10"     â”‚
â”‚    sheets_data action="read" range="G1:H10"     â”‚
â”‚    Result: 3 API calls                            â”‚
â”‚                                                    â”‚
â”‚ âœ… DO: Single batch read                          â”‚
â”‚    sheets_data action="batch_read" ranges=[    â”‚
â”‚      "A1:B10", "D1:E10", "G1:H10"               â”‚
â”‚    ]                                              â”‚
â”‚    Result: 1 API call (66% savings!)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

2ï¸âƒ£  TRANSACTIONS (80-95% savings for bulk)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âŒ DON'T: Individual write operations              â”‚
â”‚    For 100 rows: 100 API calls                   â”‚
â”‚                                                    â”‚
â”‚ âœ… DO: Transaction-wrapped bulk operation         â”‚
â”‚    sheets_transaction action="begin"             â”‚
â”‚    For chunks: queue write operations            â”‚
â”‚    sheets_transaction action="commit"            â”‚
â”‚    Result: 1 API call (99% savings!)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

3ï¸âƒ£  CACHING (15-30% savings)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â€¢ Metadata (sheet list, properties) cached       â”‚
â”‚ â€¢ Frequently-read ranges cached                  â”‚
â”‚ â€¢ Cache auto-invalidates on writes               â”‚
â”‚                                                    â”‚
â”‚ Tip: Don't repeatedly call sheets_core getâ”‚
â”‚      Results cached automatically                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“ˆ PHASE 4: STRUCTURE OPTIMIZATION

Run Full Analysis:
sheets_analyze action="analyze_structure"

Common Issues & Fixes:

1. Duplicate Headers:
   Problem: Multiple columns named "Date"
   Fix: sheets_core action="update_sheet" â†’ Rename to unique names

2. Mixed Data Types in Columns:
   Problem: "Age" column has numbers and text
   Fix: sheets_analyze â†’ Find inconsistencies â†’ Clean data

3. Unnecessary Sheets:
   Problem: 20 sheets, only 5 used
   Fix: Archive or delete unused sheets

4. Inefficient Layouts:
   Problem: Wide sheets (50+ columns)
   Fix: Consider pivot tables or transposed layout

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“‹ PHASE 5: GENERATE AUDIT REPORT

Create Audit Report Sheet:
sheets_core action="add_sheet" title="Performance_Audit_Report"

Report Sections:

1. EXECUTIVE SUMMARY
   â€¢ Overall Performance Score: X/100
   â€¢ Critical Issues: N
   â€¢ Est. Speed Improvement: Y%
   â€¢ Est. API Savings: Z%

2. FORMULA ANALYSIS
   â€¢ Total Formulas: N
   â€¢ Volatile Functions: N (replace with static)
   â€¢ VLOOKUPs to Optimize: N (convert to INDEX/MATCH)
   â€¢ Circular References: N (fix immediately)

3. STRUCTURE RECOMMENDATIONS
   â€¢ Sheets to Split: [List]
   â€¢ Empty Rows to Remove: N
   â€¢ Duplicate Columns: [List]

4. API EFFICIENCY
   â€¢ Current: X% efficiency
   â€¢ Potential: Y% efficiency (+Z% improvement)
   â€¢ Recommendation: Use batching + transactions

5. ACTION PLAN (Prioritized)
   Priority 1 (Critical):
     â€¢ Fix circular references
     â€¢ Remove volatile functions from large ranges
     â€¢ Split sheets >100K cells

   Priority 2 (High):
     â€¢ Convert VLOOKUP to INDEX/MATCH
     â€¢ Implement batching for repeated operations
     â€¢ Clean up empty rows

   Priority 3 (Medium):
     â€¢ Optimize data structure
     â€¢ Add named ranges
     â€¢ Implement caching strategy

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ’¡ QUICK WINS (Implement These First)

1. Enable Batching: Use batch_read instead of individual reads
   Impact: 20-40% API savings immediately

2. Fix Volatile Functions: Replace NOW() with manual timestamps
   Impact: 80% recalculation reduction

3. Delete Empty Rows: sheets_dimensions action="delete_rows"
   Impact: Faster load times, cleaner data

4. Use Transactions: Wrap bulk operations
   Impact: 80-95% API savings for bulk ops

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Audit complete! Review findings and implement recommendations. ğŸ¯`,
            },
          },
        ],
      };
    }
  );

  server.registerPrompt(
    'batch_optimizer',
    {
      description: 'ğŸ”„ Convert inefficient individual operations to optimized batch operations',
      argsSchema: BatchOptimizerPromptArgsSchema,
    },
    async (args: Record<string, unknown>) => {
      const operationType = args['operationType'] as string;
      const operationCount = (args['operationCount'] as number) || 10;

      return {
        messages: [
          {
            role: 'user' as const,
            content: {
              type: 'text' as const,
              text: `ğŸ”„ Batch Operation Optimizer

Spreadsheet: ${args['spreadsheetId']}
Operation Type: ${operationType}
Current: ${operationCount} individual operations

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“Š CURRENT INEFFICIENCY ANALYSIS

${
  operationType === 'read'
    ? `
**READING ${operationCount} RANGES INDIVIDUALLY**

âŒ Current Approach (INEFFICIENT):
\`\`\`
For each of ${operationCount} ranges:
  sheets_data action="read" range="..."
  Wait for response
  Process data
\`\`\`

Cost Analysis:
â€¢ API Calls: ${operationCount}
â€¢ Time: ~${operationCount * 0.3}s (${operationCount}Ã— 300ms average)
â€¢ Quota Usage: ${operationCount} read requests
â€¢ Failure Risk: ${operationCount} opportunities for errors

âœ… Optimized Approach (BATCH READ):
\`\`\`
sheets_data action="batch_read" ranges=[
  "Sheet1!A1:B10",
  "Sheet1!D1:E10",
  ...${operationCount} ranges
]
\`\`\`

Savings Analysis:
â€¢ API Calls: 1 (${operationCount - 1} saved!)
â€¢ Time: ~0.5s (${(operationCount * 0.3 - 0.5).toFixed(1)}s faster)
â€¢ Quota Savings: ${(((operationCount - 1) / operationCount) * 100).toFixed(0)}%
â€¢ Failure Risk: 1 call to monitor

ğŸ¯ IMPROVEMENT: ${(((operationCount - 1) / operationCount) * 100).toFixed(0)}% fewer API calls
`
    : operationType === 'write'
      ? `
**WRITING ${operationCount} RANGES INDIVIDUALLY**

âŒ Current Approach (INEFFICIENT):
\`\`\`
For each of ${operationCount} ranges:
  sheets_data action="write"
    range="..."
    values=[...]
\`\`\`

Cost: ${operationCount} API calls

âœ… Option 1: Batch Write (Moderate Improvement)
\`\`\`
sheets_data action="batch_write" data=[
  {range: "A1:B10", values: [...]},
  {range: "D1:E10", values: [...]},
  ...${operationCount} writes
]
\`\`\`
Savings: ${(((operationCount - 1) / operationCount) * 100).toFixed(0)}% fewer API calls

âœ… Option 2: Transaction (BEST - Atomic)
\`\`\`
sheets_transaction action="begin"
  â†’ transactionId

For each write:
  sheets_transaction action="queue"
    transactionId=...
    operation={write details}

sheets_transaction action="commit"
  transactionId=...
\`\`\`

Benefits:
â€¢ API Calls: 3 total (begin + queueÃ—N + commit = 1 actual API call)
â€¢ **Atomicity**: All succeed or all fail (no partial writes)
â€¢ **Rollback**: Auto-rollback on error
â€¢ **Performance**: 80-95% faster
â€¢ **Quota Savings**: ${Math.floor(((operationCount - 3) / operationCount) * 100)}%

ğŸ¯ IMPROVEMENT: ${Math.floor(((operationCount - 3) / operationCount) * 100)}% fewer API calls + atomicity guarantee
`
      : operationType === 'update'
        ? `
**UPDATING ${operationCount} CELLS/RANGES**

âŒ Current Approach:
Multiple individual update calls

âœ… Optimized: Use sheets_composite bulk_update

sheets_composite action="bulk_update"
  spreadsheetId="${args['spreadsheetId']}"
  sheet="Sheet1"
  keyColumn="ID"
  updates=[
    {ID: 1, Name: "New Name", Status: "Active"},
    {ID: 2, Price: 99.99},
    ...${operationCount} updates
  ]

Features:
â€¢ Updates by key column (like SQL UPDATE WHERE)
â€¢ Only modifies specified fields
â€¢ Preserves other columns
â€¢ Single API call
â€¢ Automatic row matching

ğŸ¯ IMPROVEMENT: ${operationCount} operations â†’ 1 API call
`
        : operationType === 'format'
          ? `
**FORMATTING ${operationCount} RANGES**

âŒ Current Approach:
Multiple sheets_format calls

âœ… Optimized: Transaction-wrapped formatting

sheets_transaction action="begin"

Queue all format operations:
  sheets_transaction action="queue" operation={
    tool: "sheets_format",
    action: "set_background_color",
    params: {range: "A1:B10", color: {red: 1}}
  }
  ...${operationCount} format operations

sheets_transaction action="commit"

Result: All ${operationCount} formats applied in 1 API call!

ğŸ¯ IMPROVEMENT: 80-95% faster, atomic formatting
`
          : `
**MIXED OPERATIONS (${operationCount} TOTAL)**

For mixed operation types, use Transaction Manager:

âœ… Optimized Workflow:

Step 1: Begin Transaction
\`\`\`
sheets_transaction action="begin"
  spreadsheetId="${args['spreadsheetId']}"
  autoRollback=true
â†’ Returns: transactionId="tx_..."
\`\`\`

Step 2: Queue All Operations
\`\`\`
// Read operation
sheets_transaction action="queue"
  transactionId="tx_..."
  operation={
    tool: "sheets_data",
    action: "read",
    params: {range: "A1:B10"}
  }

// Write operation
sheets_transaction action="queue"
  transactionId="tx_..."
  operation={
    tool: "sheets_data",
    action: "write",
    params: {range: "D1:E10", values: [...]}
  }

// Format operation
sheets_transaction action="queue"
  transactionId="tx_..."
  operation={
    tool: "sheets_format",
    action: "set_bold",
    params: {range: "A1:B1", bold: true}
  }

...repeat for all ${operationCount} operations
\`\`\`

Step 3: Commit Transaction
\`\`\`
sheets_transaction action="commit"
  transactionId="tx_..."
\`\`\`

Result: All ${operationCount} operations execute in single API call!

Benefits:
â€¢ ${operationCount} â†’ 1 API call (${Math.floor(((operationCount - 1) / operationCount) * 100)}% reduction)
â€¢ Atomic execution (all-or-nothing)
â€¢ Auto-rollback on failure
â€¢ Preserves operation order
â€¢ ${Math.floor(((operationCount - 1) / operationCount) * 100)}% quota savings

ğŸ¯ IMPROVEMENT: ${Math.floor(((operationCount - 1) / operationCount) * 100)}% API reduction + atomicity
`
}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“‹ IMPLEMENTATION GUIDE

${
  operationType === 'read'
    ? `
**Step-by-Step: Convert to Batch Read**

1. Collect all ranges to read:
   ranges = ["Sheet1!A1:B10", "Sheet1!D1:E10", ...]

2. Single batch read call:
   sheets_data action="batch_read"
     spreadsheetId="${args['spreadsheetId']}"
     ranges=ranges

3. Process results:
   Response includes all range data in one object
   Access via response.valueRanges[i]

Example:
\`\`\`json
{
  "action": "batch_read",
  "spreadsheetId": "${args['spreadsheetId']}",
  "ranges": [
    "Sheet1!A1:B10",
    "Sheet1!D1:E10",
    "Sheet2!A1:Z100"
  ]
}
\`\`\`

Result: 1 API call instead of ${operationCount}!
`
    : operationType === 'write'
      ? `
**Step-by-Step: Convert to Transaction**

1. Begin Transaction:
\`\`\`json
{
  "tool": "sheets_transaction",
  "action": "begin",
  "spreadsheetId": "${args['spreadsheetId']}",
  "autoRollback": true
}
\`\`\`
â†’ Save transactionId from response

2. Queue Each Write:
\`\`\`json
{
  "tool": "sheets_transaction",
  "action": "queue",
  "transactionId": "tx_...",
  "operation": {
    "tool": "sheets_data",
    "action": "write",
    "params": {
      "spreadsheetId": "${args['spreadsheetId']}",
      "range": "A1:B10",
      "values": [[1, 2], [3, 4], ...]
    }
  }
}
\`\`\`
Repeat for all ${operationCount} writes

3. Commit Transaction:
\`\`\`json
{
  "tool": "sheets_transaction",
  "action": "commit",
  "transactionId": "tx_..."
}
\`\`\`

Done! All ${operationCount} writes in 1 API call with atomicity.
`
      : `
**Step-by-Step: Transaction for Mixed Operations**

1. Plan operations:
   â€¢ Group by dependency (reads before writes that use read data)
   â€¢ List all operations

2. Begin transaction:
   sheets_transaction action="begin"

3. Queue in order:
   For each operation:
     sheets_transaction action="queue" operation={...}

4. Commit:
   sheets_transaction action="commit"

5. Verify:
   Check response for success
   All operations executed atomically
`
}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ’¡ BEST PRACTICES

1. **Batch Size**: Aim for 10-100 operations per batch
   â€¢ Too small: Less efficiency gain
   â€¢ Too large: Longer request timeout risk

2. **Error Handling**: Transactions auto-rollback on failure
   â€¢ No partial state
   â€¢ Retry entire transaction

3. **Progress Tracking**: For large batches (>100 ops)
   â€¢ Break into multiple transactions
   â€¢ Commit after each batch
   â€¢ Track progress externally

4. **Testing**: Always test with small batch first
   â€¢ Verify operation ordering
   â€¢ Check data correctness
   â€¢ Then scale to full batch size

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“Š EXPECTED RESULTS

Before Optimization:
â€¢ API Calls: ${operationCount}
â€¢ Time: ~${(operationCount * 0.3).toFixed(1)}s
â€¢ Failure Risk: ${operationCount} points
â€¢ Quota Usage: ${operationCount} requests

After Optimization:
â€¢ API Calls: ${operationType === 'write' || operationType === 'mixed' ? '3 (1 effective)' : '1'}
â€¢ Time: ~0.5-1s
â€¢ Failure Risk: 1 point
â€¢ Quota Saved: ${Math.floor(((operationCount - (operationType === 'write' || operationType === 'mixed' ? 3 : 1)) / operationCount) * 100)}%

**Performance Gain: ${Math.floor(((operationCount - (operationType === 'write' || operationType === 'mixed' ? 3 : 1)) / operationCount) * 100)}% fewer API calls** âš¡

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Ready to optimize! Convert your operations now. ğŸš€`,
            },
          },
        ],
      };
    }
  );

  // === ULTIMATE ANALYSIS TOOL PROMPTS (P2) ===

  server.registerPrompt(
    'ultimate_analysis',
    {
      description: 'ğŸ§  Ultimate Analysis Tool - Intelligent routing for data analysis',
      argsSchema: UltimateAnalysisPromptArgsSchema,
    },
    async (args: Record<string, unknown>) => {
      return {
        messages: [
          {
            role: 'user' as const,
            content: {
              type: 'text' as const,
              text: `ğŸ§  Ultimate Analysis Tool

Spreadsheet: ${args['spreadsheetId']}

## ğŸ¯ INTELLIGENT ROUTING

The analysis tool automatically selects the optimal execution path:

**Fast Path** (<10K cells)
â€¢ Traditional statistics
â€¢ Completes in <2s
â€¢ Best for: Quick summaries, small datasets

**AI Path** (10K-50K cells)
â€¢ LLM-powered insights via MCP Sampling
â€¢ Completes in <15s
â€¢ Best for: Deep insights, pattern detection, recommendations

**Streaming Path** (>50K cells)
â€¢ Task-based chunked processing
â€¢ Async execution with progress tracking
â€¢ Best for: Large datasets, comprehensive analysis

## ğŸ“Š USAGE

Basic Analysis:
\`\`\`json
{
  "tool": "sheets_analyze",
  "action": "analyze_data",
  "spreadsheetId": "${args['spreadsheetId']}",
  "analysisTypes": ["summary", "quality", "patterns"]
}
\`\`\`

The router will:
1. Fetch metadata (tier 1, ~0.3s)
2. Determine dataset size
3. Select optimal path (fast/AI/streaming)
4. Execute analysis
5. Store result as \`analyze://results/{id}\`

## ğŸ” ANALYSIS TYPES

â€¢ **summary**: Overall data summary
â€¢ **patterns**: Pattern recognition
â€¢ **anomalies**: Outlier detection
â€¢ **trends**: Trend analysis
â€¢ **quality**: Data quality assessment
â€¢ **correlations**: Relationship discovery
â€¢ **recommendations**: Actionable suggestions

## ğŸ’¡ TIPS

1. **Small datasets (<10K)**: Fast path is sufficient
2. **Medium datasets (10K-50K)**: AI path provides best insights
3. **Large datasets (>50K)**: Streaming path handles without timeout
4. **Follow-up analysis**: Reference previous results via \`analyze://results/{id}\`

Ready to analyze! What insights do you need? ğŸš€`,
            },
          },
        ],
      };
    }
  );

  server.registerPrompt(
    'create_visualization',
    {
      description: 'ğŸ“Š Create charts/pivots with AI recommendations and user confirmation',
      argsSchema: CreateVisualizationPromptArgsSchema,
    },
    async (args: Record<string, unknown>) => {
      return {
        messages: [
          {
            role: 'user' as const,
            content: {
              type: 'text' as const,
              text: `ğŸ“Š Create Visualization with AI

Spreadsheet: ${args['spreadsheetId']}

## ğŸ¨ WORKFLOW (3 Steps)

**Step 1: Get Recommendations**
\`\`\`json
{
  "tool": "sheets_analyze",
  "action": "suggest_visualization",
  "spreadsheetId": "${args['spreadsheetId']}",
  "range": { "a1": "Sheet1!A1:D100" }
}
\`\`\`

AI will analyze your data and suggest:
â€¢ Best chart types (LINE, BAR, PIE, SCATTER, etc.)
â€¢ Optimal data ranges
â€¢ Axis configurations
â€¢ Pivot table dimensions

**Step 2: User Confirmation (Automatic)**

When you create a chart/pivot, MCP Elicitation will prompt:
\`\`\`
âš ï¸ Create Chart

You are about to create a LINE chart in spreadsheet ${args['spreadsheetId']}.

The chart will use data from range A1:D100.

This will modify the spreadsheet by adding a new chart object.

[ Confirm ] [ Cancel ]
\`\`\`

**Step 3: Create**
\`\`\`json
{
  "tool": "sheets_analyze",
  "action": "create_recommended_chart",
  "spreadsheetId": "${args['spreadsheetId']}",
  "chartType": "LINE",
  "range": { "a1": "Sheet1!A1:D100" }
}
\`\`\`

## ğŸ“ˆ CHART TYPES AVAILABLE

â€¢ LINE: Time series, trends
â€¢ BAR: Comparisons, rankings
â€¢ COLUMN: Category comparisons
â€¢ PIE: Part-to-whole relationships
â€¢ SCATTER: Correlation analysis
â€¢ AREA: Volume over time
â€¢ COMBO: Multiple metrics
â€¢ STEPPED_AREA: Staged progress

## ğŸ”„ PIVOT TABLES

For pivot tables:
\`\`\`json
{
  "tool": "sheets_analyze",
  "action": "create_recommended_pivot",
  "spreadsheetId": "${args['spreadsheetId']}",
  "range": { "a1": "Data!A1:F1000" }
}
\`\`\`

Creates a new sheet with pivot table automatically!

## ğŸ›¡ï¸ SAFETY FEATURES

â€¢ User confirmation via MCP Elicitation (SEP-1036)
â€¢ Rollback support if creation fails
â€¢ Validation before modification
â€¢ Clear error messages

Ready to visualize your data! ğŸ¨`,
            },
          },
        ],
      };
    }
  );

  server.registerPrompt(
    'analyze_with_history',
    {
      description: 'ğŸ”— Reference previous analysis results via MCP Resources',
      argsSchema: AnalyzeWithHistoryPromptArgsSchema,
    },
    async (args: Record<string, unknown>) => {
      return {
        messages: [
          {
            role: 'user' as const,
            content: {
              type: 'text' as const,
              text: `ğŸ”— Analysis History via MCP Resources

Spreadsheet: ${args['spreadsheetId']}

## ğŸ“š STORED ANALYSIS RESULTS

Every successful \`analyze_data\` is automatically stored as an MCP Resource:
\`analyze://results/{id}\`

## ğŸ” AVAILABLE RESOURCES

**List all recent analyses:**
\`\`\`
Resource: analyze://results
\`\`\`

Returns:
\`\`\`json
{
  "count": 5,
  "results": [
    {
      "id": "analysis-1",
      "spreadsheetId": "${args['spreadsheetId']}",
      "timestamp": "2026-01-12T10:30:00Z",
      "summary": "Fast statistical analysis complete...",
      "uri": "analyze://results/analysis-1"
    }
  ]
}
\`\`\`

**Get specific analysis:**
\`\`\`
Resource: analyze://results/analysis-1
\`\`\`

Returns full analysis result with all findings.

## ğŸ’¬ CONVERSATIONAL WORKFLOWS

**Pattern 1: Compare with Previous**
\`\`\`
User: "Analyze Sheet1"
Assistant: [Runs analyze_data, stores as analysis-1]
          "...completed (stored as analyze://results/analysis-1)"

User: "How does this compare to last week?"
Assistant: [Reads analyze://results/analysis-1]
           "Last week's quality score was 85, now it's 92..."
\`\`\`

**Pattern 2: Explain Previous Analysis**
\`\`\`json
{
  "tool": "sheets_analyze",
  "action": "explain_analysis",
  "analysisResult": { /* from analyze://results/analysis-1 */ },
  "question": "Why did quality improve?"
}
\`\`\`

**Pattern 3: Track Quality Over Time**
\`\`\`
1. List: analyze://results
2. Filter: analyses for same spreadsheet
3. Compare: quality scores over time
4. Report: "Quality improving by 5% per week"
\`\`\`

## ğŸ“Š OTHER ANALYSIS RESOURCES

â€¢ \`analyze://stats\` - Service statistics (success rate, avg time)
â€¢ \`analyze://help\` - Full analysis documentation

## ğŸ¯ BENEFITS

âœ… No need to re-run analyses
âœ… Reference previous results in follow-up questions
âœ… Track data quality over time
âœ… Compare before/after cleanup
âœ… MCP-native (standard resource protocol)

## ğŸ’¾ STORAGE

â€¢ Last 100 analyses kept in memory
â€¢ Automatic cleanup of old results
â€¢ No manual storage required
â€¢ Access via standard MCP resource URIs

Ready to leverage analysis history! ğŸ”—`,
            },
          },
        ],
      };
    }
  );

  // === INTERACTIVE LEARNING PROMPTS (Phase 4: Optional Enhancements) ===

  server.registerPrompt(
    'masterclass_data_quality',
    {
      description: 'ğŸ“Š Interactive data quality analysis tutorial',
      argsSchema: MasterClassDataQualityPromptArgsSchema,
    },
    async ({ spreadsheetId, level }) => {
      const selectedLevel = level || 'beginner';
      const spreadsheetContext = spreadsheetId
        ? `\n\nPractice spreadsheet: ${spreadsheetId}`
        : '\n\nCreate a test spreadsheet to practice';

      return {
        messages: [
          {
            role: 'user' as const,
            content: {
              type: 'text' as const,
              text: `# ğŸ“Š Data Quality Master Class - ${selectedLevel.toUpperCase()} Level

${
  selectedLevel === 'beginner'
    ? `
## Module 1: Understanding Quality Scores

### What is Data Quality?
Data quality measures how reliable and usable your spreadsheet data is. ServalSheets analyzes 15 different quality dimensions:

- **Completeness**: Are there missing values?
- **Consistency**: Do similar cells have similar formats?
- **Accuracy**: Are formulas error-free?
- **Validity**: Do values make sense in context?

### Quality Score Scale
- **90-100%**: Excellent (production-ready)
- **70-89%**: Good (minor issues)
- **50-69%**: Fair (needs attention)
- **Below 50%**: Poor (critical issues)

## Your First Analysis

**Step 1: Run a Scout Analysis**
\`\`\`
sheets_analyze action:"scout" spreadsheetId:"YOUR_ID"
\`\`\`

Scout mode is fast (~200ms) and gives you:
- Overall quality score
- Top 3 issues
- Recommended next steps

**Step 2: Interpret Results**
If quality < 80%, run:
\`\`\`
sheets_analyze action:"comprehensive" spreadsheetId:"YOUR_ID"
\`\`\`

This reveals:
- Detailed breakdown by issue type
- Cell-level examples
- Actionable fix suggestions
`
    : ''
}${
                selectedLevel === 'intermediate'
                  ? `
## Module 2: Advanced Quality Patterns

### Pattern Detection
Learn to identify common quality problems:

**Pattern 1: Mixed Data Types**
\`\`\`
Column A: [123, "456", 789, "N/A"]
Issue: Numbers mixed with text
Impact: SUM() fails, charts break
Fix: sheets_fix action:"fix_types"
\`\`\`

**Pattern 2: Inconsistent Formats**
\`\`\`
Date column: ["01/15/2024", "2024-01-16", "Jan 17, 2024"]
Issue: Multiple date formats
Impact: Sorting breaks, comparisons fail
Fix: sheets_fix action:"standardize_formats"
\`\`\`

**Pattern 3: Formula Errors**
\`\`\`
#REF! errors: Broken cell references
#DIV/0! errors: Division by zero
#N/A errors: VLOOKUP failures
\`\`\`

## Your Challenge

Run a comprehensive analysis and:
1. Identify the TOP issue by impact
2. Estimate fix time (use sheets_quality analyze_impact)
3. Create a fix plan with preview mode
4. Execute fixes
5. Re-analyze to verify improvement
`
                  : ''
              }${
                selectedLevel === 'advanced'
                  ? `
## Module 3: Quality Monitoring & Automation

### Building Quality Gates
Prevent quality degradation with automated checks:

**Strategy 1: Pre-write Validation**
\`\`\`
Before: sheets_data write
Run: sheets_quality validate
If quality drop > 15%: Alert user, cancel write
\`\`\`

**Strategy 2: Periodic Scout**
\`\`\`
sheets_session set_pending type:"quality_monitoring"
Every 10 operations: sheets_analyze scout
If quality < threshold: Trigger alert
\`\`\`

**Strategy 3: Historical Tracking**
\`\`\`
Store quality scores in sheets_session
Track quality trends over time
Alert if 3 consecutive drops
\`\`\`

## Production Pattern

Implement this workflow:
1. Baseline: Run comprehensive analysis at start
2. Monitor: Scout every 10-15 operations
3. Alert: Quality drop > 15% triggers warning
4. Fix: Auto-suggest fixes with preview
5. Verify: Re-analyze after fixes
6. Learn: Track patterns in quality changes

Try implementing this pattern on your spreadsheet!
`
                  : ''
              }${spreadsheetContext}

## ğŸ¯ Common Mistakes to Avoid

1. **Ignoring low-impact issues**: Fix high-impact issues first
2. **Skipping preview mode**: Always preview fixes before applying
3. **Not re-analyzing**: Verify quality improved after fixes
4. **Treating all issues equally**: Prioritize by impact score

## ğŸ“š Next Steps

- ${selectedLevel === 'beginner' ? 'Try Module 2 (intermediate level) when ready' : ''}
- ${selectedLevel === 'intermediate' ? 'Try Module 3 (advanced level) when ready' : ''}
- ${selectedLevel === 'advanced' ? 'Build a quality monitoring workflow' : ''}
- Practice on real spreadsheets
- Try challenge_quality_detective for a hands-on mystery

Ready to analyze some data! ğŸ”`,
            },
          },
        ],
      };
    }
  );

  server.registerPrompt(
    'masterclass_formulas',
    {
      description: 'ğŸ“ Formula optimization workshop',
      argsSchema: MasterClassFormulasPromptArgsSchema,
    },
    async ({ topic }) => {
      const selectedTopic = topic || 'performance';

      return {
        messages: [
          {
            role: 'user' as const,
            content: {
              type: 'text' as const,
              text: `# ğŸ“ Formula Optimization Workshop: ${selectedTopic.replace(/_/g, ' ').toUpperCase()}

${
  selectedTopic === 'performance'
    ? `
## Formula Performance Hierarchy

**Fastest â†’ Slowest:**
1. âš¡ Static values (instant)
2. âš¡ Simple arithmetic (+, -, *, /)
3. âœ… Basic functions (SUM, AVERAGE, COUNT)
4. âœ… Lookup functions (VLOOKUP, INDEX/MATCH)
5. âš ï¸ Array formulas (FILTER, SORT, UNIQUE)
6. ğŸŒ Volatile functions (NOW, TODAY, RAND)
7. ğŸŒ External data (IMPORTRANGE, GOOGLEFINANCE)
8. ğŸŒ Apps Script custom functions

## Example: Slow vs Fast

**Slow (500ms):**
\`\`\`
=ARRAYFORMULA(IF(A2:A1000<>"", VLOOKUP(A2:A1000, Sheet2!A:B, 2, FALSE), ""))
\`\`\`
Problem: ARRAYFORMULA evaluates row-by-row

**Fast (50ms):**
\`\`\`
=QUERY(Sheet2!A:B, "SELECT B WHERE A = '"&A2&"'")
\`\`\`
Why: QUERY is optimized by Google

## Your Challenge

Find a slow formula in your spreadsheet:
1. Use sheets_analyze analyze_performance
2. Identify formulas taking >100ms
3. Rewrite using QUERY or INDEX/MATCH
4. Measure improvement
`
    : ''
}${
                selectedTopic === 'array_formulas'
                  ? `
## Array Formula Best Practices

**When to Use Array Formulas:**
- âœ… Data changes frequently (auto-updates)
- âœ… Multiple conditions needed
- âœ… Result needs to expand dynamically
- âœ… Working with <10K rows

**When to Avoid:**
- âŒ >50K rows (use helper columns)
- âŒ Volatile functions inside (NOW, RAND)
- âŒ Complex nested logic (hard to debug)

## Optimization Examples

**Example 1: Conditional Formatting**
Slow:
\`\`\`
=ARRAYFORMULA(IF(B2:B>100, "High", IF(B2:B>50, "Medium", "Low")))
\`\`\`

Fast:
\`\`\`
=ARRAYFORMULA(IFS(B2:B>100, "High", B2:B>50, "Medium", B2:B>0, "Low", TRUE, ""))
\`\`\`
IFS is faster than nested IF

**Example 2: Lookup with Default**
Slow:
\`\`\`
=ARRAYFORMULA(IF(A2:A<>"", IFERROR(VLOOKUP(A2:A, Sheet2!A:B, 2, FALSE), "Not Found"), ""))
\`\`\`

Fast:
\`\`\`
=ARRAYFORMULA(IFNA(VLOOKUP(A2:A, Sheet2!A:B, 2, FALSE), "Not Found"))
\`\`\`
IFNA is faster than IFERROR for VLOOKUP
`
                  : ''
              }${
                selectedTopic === 'volatile_functions'
                  ? `
## Volatile Function Management

### The Problem
Volatile functions recalculate on EVERY sheet edit:
- NOW() - Current date/time
- TODAY() - Current date
- RAND() / RANDBETWEEN() - Random numbers
- INDIRECT() - Dynamic cell references

**Impact:** Slows down the ENTIRE sheet for ALL users

### The Solution

**Pattern 1: Centralize Volatility**
Bad:
\`\`\`
A1: =NOW()
A2: =NOW()
A3: =NOW()
\`\`\`
(Recalculates 3 times per edit)

Good:
\`\`\`
A1: =NOW()
A2: =A1
A3: =A1
\`\`\`
(Recalculates once per edit)

**Pattern 2: Named Range**
1. Create named range "CurrentDate" pointing to A1
2. Put =NOW() in A1
3. Use =CurrentDate everywhere else

**Pattern 3: Apps Script Alternative**
For time-based updates:
\`\`\`
sheets_appsscript action:"time_trigger"
  script: "Update timestamp cell every 5 minutes"
\`\`\`

## Your Task

Audit your spreadsheet:
1. sheets_analyze analyze_performance checkVolatility:true
2. Count volatile functions
3. Refactor if count >10
4. Measure before/after performance
`
                  : ''
              }${
                selectedTopic === 'lookup_optimization'
                  ? `
## Lookup Formula Optimization

### VLOOKUP vs INDEX/MATCH vs XLOOKUP

**VLOOKUP:**
- âœ… Simple syntax
- âœ… Fast for small data (<1K rows)
- âŒ Only searches left-to-right
- âŒ Breaks if columns change

**INDEX/MATCH:**
- âœ… Searches any direction
- âœ… Faster on large data (>10K rows)
- âœ… Flexible (doesn't break on column changes)
- âŒ More complex syntax

**XLOOKUP (newer):**
- âœ… Most powerful
- âœ… Best syntax
- âŒ Not available in all sheets

### Performance Comparison

**10K rows benchmark:**
- VLOOKUP: ~200ms
- INDEX/MATCH: ~50ms
- QUERY: ~30ms

## Examples

**VLOOKUP:**
\`\`\`
=VLOOKUP(A2, Sheet2!A:B, 2, FALSE)
\`\`\`

**INDEX/MATCH (4x faster):**
\`\`\`
=INDEX(Sheet2!B:B, MATCH(A2, Sheet2!A:A, 0))
\`\`\`

**QUERY (6x faster):**
\`\`\`
=QUERY(Sheet2!A:B, "SELECT B WHERE A = '"&A2&"'", 0)
\`\`\`

## Your Challenge

Convert VLOOKUPs to INDEX/MATCH:
1. Find VLOOKUPs: sheets_analyze audit_formulas
2. Rewrite top 5 slowest ones
3. Benchmark improvement
`
                  : ''
              }${
                selectedTopic === 'error_handling'
                  ? `
## Formula Error Handling

### Common Errors
- #REF! - Broken cell reference
- #DIV/0! - Division by zero
- #N/A - VLOOKUP/MATCH not found
- #VALUE! - Wrong data type
- #NAME? - Unknown function name

### Error Handling Strategies

**Strategy 1: IFERROR (Universal)**
\`\`\`
=IFERROR(formula, "fallback_value")
\`\`\`
Catches all errors, returns fallback

**Strategy 2: IFNA (Lookup-Specific)**
\`\`\`
=IFNA(VLOOKUP(...), "Not Found")
\`\`\`
Only catches #N/A, faster than IFERROR

**Strategy 3: IF + ISERROR (Conditional)**
\`\`\`
=IF(ISERROR(formula), "handle_error", formula)
\`\`\`
Different handling for error vs success

**Strategy 4: Defensive Formulas**
\`\`\`
=IF(B2=0, 0, A2/B2)  // Prevent #DIV/0!
=IF(ISBLANK(A2), "", VLOOKUP(...))  // Prevent #N/A
\`\`\`

## Best Practices

1. **Production formulas**: Always use error handling
2. **Debugging**: Remove error handling temporarily
3. **Performance**: Use IFNA for lookups (faster than IFERROR)
4. **User experience**: Return meaningful error messages

## Your Task

1. sheets_analyze audit_formulas
2. Find formulas without error handling
3. Add appropriate error handling
4. Test edge cases
`
                  : ''
              }

## ğŸ“ Pro Tips

- Use sheets_dependencies analyze_impact before changing formulas
- Test formulas on small data first
- Document complex formulas with comments
- Version control via sheets_collaborate snapshots

## ğŸ“š Next Topics

${topic ? '- Try a different topic: performance, array_formulas, volatile_functions, lookup_optimization, error_handling' : '- Specify a topic to dive deeper'}

Ready to optimize! âš¡`,
            },
          },
        ],
      };
    }
  );

  server.registerPrompt(
    'masterclass_performance',
    {
      description: 'âš¡ Performance tuning lab',
      argsSchema: MasterClassPerformancePromptArgsSchema,
    },
    async ({ spreadsheetId, focusArea }) => {
      return {
        messages: [
          {
            role: 'user' as const,
            content: {
              type: 'text' as const,
              text: `# âš¡ Performance Tuning Lab

**Target Spreadsheet:** ${spreadsheetId}

## Step 1: Baseline Measurement

Let's measure current performance:

\`\`\`
sheets_analyze action:"analyze_performance"
  spreadsheetId:"${spreadsheetId}"
  checkFormulas:true
  checkVolatility:true
\`\`\`

This will report:
- Volatile function count
- Formula complexity scores
- Circular references
- Recommended optimizations

${
  focusArea === 'read_ops'
    ? `
## Focus: Read Operation Performance

### Symptoms
- Reads taking >2 seconds
- Timeout errors
- High latency on large ranges

### Diagnosis Tree

**Check 1: Range Size**
Reading >1K rows? â†’ Use batch_read instead of multiple reads

**Check 2: Value Rendering**
Reading formatted values? â†’ Use valueRenderOption: UNFORMATTED_VALUE (3x faster)

**Check 3: Multiple Sheets**
Reading from multiple sheets? â†’ Use batch_get (parallel fetching)

**Check 4: Column Selection**
Need only specific columns? â†’ Use column ranges (A:A, C:C) not full rows

### Optimization Examples

**Before (Slow - 5 API calls, ~2.5s):**
\`\`\`
for (let i = 0; i < 5; i++) {
  await sheets_data.read(range: \`Sheet\${i}!A1:Z100\`)
}
\`\`\`

**After (Fast - 1 API call, ~500ms):**
\`\`\`
sheets_data action:"batch_read"
  ranges:["Sheet0!A1:Z100", "Sheet1!A1:Z100", ..., "Sheet4!A1:Z100"]
\`\`\`

**Even Faster (1 API call, ~300ms):**
\`\`\`
sheets_data action:"batch_read"
  ranges:[...]
  valueRenderOption:"UNFORMATTED_VALUE"
\`\`\`

### Your Task
1. Identify slow reads in your usage
2. Convert to batch_read
3. Benchmark improvement
`
    : ''
}${
                focusArea === 'write_ops'
                  ? `
## Focus: Write Operation Performance

### Symptoms
- Writes taking >5 seconds
- Rate limit errors (429)
- High quota usage

### Diagnosis Tree

**Check 1: Write Count**
Writing <100 cells? â†’ Direct sheets_data write (optimal)
Writing 100-1000 cells? â†’ Use batch_write (70% faster)
Writing >1000 cells? â†’ Use sheets_transaction (80% quota savings)

**Check 2: Formula Handling**
Writing formulas? â†’ Set formulas separately (faster than mixed values)

### Quota Impact Comparison

**Naive Approach (500 individual writes):**
- API calls: 500
- Quota used: ~500 units
- Time: ~250 seconds (30 req/min rate limit)

**Transaction Approach:**
- API calls: 3 (begin, commit with 500 operations, end)
- Quota used: ~100 units (80% savings)
- Time: ~3 seconds

**Recommendation:** Use sheets_transaction for ANY sequential write >50 cells

### Your Task
1. Estimate your typical write volume
2. If >50 cells, switch to transactions
3. Measure quota and time savings
`
                  : ''
              }${
                focusArea === 'formulas'
                  ? `
## Focus: Formula Performance

### Symptoms
- Sheet freezes on edit
- "Calculating..." appears frequently
- Lag when typing

### Diagnosis Tree

**Check 1: Volatile Functions**
Count volatile functions (NOW, TODAY, RAND)
- If >10: Consolidate to 1 cell, reference elsewhere

**Check 2: Array Formulas**
ARRAYFORMULA on >10K rows?
- Replace with helper columns
- Or use QUERY instead

**Check 3: Circular References**
Check iterative calculation settings
- sheets_dependencies detect_cycles

**Check 4: External Data**
IMPORTRANGE or GOOGLEFINANCE?
- Cache results, refresh periodically
- Use sheets_appsscript for scheduled updates

**Check 5: Complex Nesting**
Formulas with >5 levels of nesting?
- Break into intermediate steps
- Use helper columns

### Detection Command

\`\`\`
sheets_analyze action:"analyze_performance"
  spreadsheetId:"${spreadsheetId}"
  checkFormulas:true
  checkVolatility:true
\`\`\`

Returns:
- volatileFunctionCount: (red flag if >10)
- circularReferences: []
- formulaComplexity: "high"
- recommendations: [...]

### Your Task
1. Run analysis command
2. Address top 3 recommendations
3. Re-analyze to verify improvement
`
                  : ''
              }${
                focusArea === 'concurrent_users'
                  ? `
## Focus: Concurrent User Performance

### Symptoms
- Multiple users editing causes lag
- Formula recalculation delays
- Save conflicts

### Diagnosis Tree

**Check 1: User Count**
>10 simultaneous editors? â†’ Expect natural lag (Google limitation)

**Check 2: Protected Ranges**
Protected range count >50? â†’ Reduce protection granularity

**Check 3: Real-time Formulas**
IMPORTRANGE or GOOGLEFINANCE in many cells?
- Replace with periodic refreshes (sheets_appsscript triggers)

**Check 4: Conditional Formatting**
Rules covering >100K cells? â†’ Simplify rule scope

### Mitigation Pattern

**Instead of: Real-time IMPORTRANGE**
\`\`\`
=IMPORTRANGE("other-sheet", "A1:Z1000")
\`\`\`
(Recalculates on every edit)

**Use: Periodic refresh**
\`\`\`
sheets_appsscript action:"time_trigger"
  interval:"5 minutes"
  operation:"refresh_external_data"
\`\`\`
(Updates every 5 minutes)

### Your Task
1. Identify concurrent usage patterns
2. Implement periodic refresh for external data
3. Optimize protected ranges
4. Test with multiple users
`
                  : ''
              }

## Step 2: Apply Optimizations

Based on the analysis results, I'll guide you through each optimization with:
- Expected improvement (e.g., "40% faster", "70% quota savings")
- Implementation steps
- Before/after measurements

## Step 3: Verify Improvements

After optimizations:

\`\`\`
sheets_analyze action:"analyze_performance"
  spreadsheetId:"${spreadsheetId}"
  checkFormulas:true
  checkVolatility:true
\`\`\`

Compare:
- Operation times (should be 30-50% faster)
- Volatile function count (should be <10)
- Formula complexity (should be "low" or "medium")

## ğŸ¯ Performance Targets

- Read operations: <500ms
- Write operations: <2s for <1000 cells
- Formula recalculation: <1s
- Volatile functions: <5 per sheet

## ğŸ“š Next Steps

${focusArea ? '- Try another focus area: read_ops, write_ops, formulas, concurrent_users' : '- Specify a focus area for targeted optimization'}
- Implement monitoring (sheets_session alerts)
- Set up performance regression tests

Ready to optimize! Let me know which area you'd like to focus on first. âš¡`,
            },
          },
        ],
      };
    }
  );

  server.registerPrompt(
    'challenge_quality_detective',
    {
      description: 'ğŸ” Diagnose data quality issues from symptoms',
      argsSchema: ChallengeQualityDetectivePromptArgsSchema,
    },
    async ({ spreadsheetId }) => {
      return {
        messages: [
          {
            role: 'user' as const,
            content: {
              type: 'text' as const,
              text: `# ğŸ” Quality Detective Challenge

**Case File:** ${spreadsheetId}

## Your Mission

You've been called in to diagnose a spreadsheet with quality issues. Users are reporting problems, but don't know the root causes.

## Investigation Process

**Step 1: Gather Evidence**
\`\`\`
sheets_analyze action:"scout"
  spreadsheetId:"${spreadsheetId}"
\`\`\`

Quick overview (~200ms):
- Overall quality score
- Top 3 issues by impact
- Recommended next steps

**Step 2: Deep Dive**
If quality <80%, run comprehensive analysis:
\`\`\`
sheets_analyze action:"comprehensive"
  spreadsheetId:"${spreadsheetId}"
\`\`\`

Detailed breakdown:
- All 15 quality dimensions
- Cell-level examples
- Root cause identification

**Step 3: Diagnose Root Causes**

Common quality patterns:
- **Mixed data types**: Numbers stored as text
- **Inconsistent formats**: Multiple date formats
- **Formula errors**: #REF!, #DIV/0!, #N/A
- **Duplicate rows**: Exact or fuzzy duplicates
- **Outliers**: Values outside normal range
- **Missing values**: Empty cells in critical columns

**Step 4: Prioritize Fixes**

Use impact score to prioritize:
\`\`\`
sheets_quality action:"analyze_impact"
  spreadsheetId:"${spreadsheetId}"
\`\`\`

Returns:
- Estimated fix time
- Quality improvement projection
- Dependency analysis

**Step 5: Preview Solutions**
\`\`\`
sheets_fix action:"preview"
  spreadsheetId:"${spreadsheetId}"
  issueType:"mixed_types"
\`\`\`

See exact changes before applying

**Step 6: Execute Fixes**
\`\`\`
sheets_fix action:"fix_all"
  spreadsheetId:"${spreadsheetId}"
  preview:false
\`\`\`

Apply all high-impact fixes

**Step 7: Verify Improvement**
\`\`\`
sheets_analyze action:"scout"
  spreadsheetId:"${spreadsheetId}"
\`\`\`

Confirm quality score improved

## Scoring Rubric

- **30 points**: Correct root cause diagnosis
- **30 points**: Optimal tool selection for fixes
- **30 points**: Complete resolution (quality >80%)
- **10 points**: Efficient approach (<5 operations)

## ğŸ¯ Detective Tips

1. Start with scout for quick triage
2. Use comprehensive only if needed (slower)
3. Check analyze_impact before fixing (prioritize high-impact)
4. Always preview fixes first (avoid surprises)
5. Re-analyze after fixes (verify improvement)

## ğŸš¨ Common Mistakes

- âŒ Fixing low-impact issues first
- âŒ Skipping preview mode
- âŒ Not re-analyzing after fixes
- âŒ Treating all issues equally

## Ready to Investigate?

Run your first command and tell me what you find. I'll guide you through the diagnosis process and reveal the actual issues after you've made your assessment.

Good luck, detective! ğŸ•µï¸`,
            },
          },
        ],
      };
    }
  );

  server.registerPrompt(
    'challenge_performance_profiler',
    {
      description: 'âš¡ Identify and fix performance bottlenecks',
      argsSchema: ChallengePerformanceProfilerPromptArgsSchema,
    },
    async ({ spreadsheetId }) => {
      return {
        messages: [
          {
            role: 'user' as const,
            content: {
              type: 'text' as const,
              text: `# âš¡ Performance Profiler Challenge

**Target Spreadsheet:** ${spreadsheetId}

## The Situation

Users are complaining that the spreadsheet is slow:
- Operations take >5 seconds
- Typing has noticeable lag
- Multiple users experience freezes

Your job: Profile, diagnose, and fix performance issues.

## Challenge Goal

**Target Improvements:**
- Reduce operation time by >40%
- Reduce formula recalculation time by >50%
- Achieve quality score >80%

**Time Limit:** 15 minutes

## Profiling Checklist

**â¬œ Step 1: Baseline Measurement**
\`\`\`
sheets_analyze action:"analyze_performance"
  spreadsheetId:"${spreadsheetId}"
  checkFormulas:true
  checkVolatility:true
\`\`\`

Record:
- Current operation time: ___ms
- Volatile function count: ___
- Formula complexity: ___
- Quality score: ___%

**â¬œ Step 2: Identify Top 3 Bottlenecks**

Analyze results and rank:
1. Bottleneck #1: ___ (estimated impact: __%)
2. Bottleneck #2: ___ (estimated impact: __%)
3. Bottleneck #3: ___ (estimated impact: __%)

Common bottlenecks:
- Too many volatile functions (NOW, RAND)
- Slow array formulas on large data
- IMPORTRANGE in many cells
- >50 protected ranges
- Complex nested formulas (>5 levels)

**â¬œ Step 3: Propose Optimization Strategy**

For each bottleneck, propose:
- Specific optimization approach
- Expected improvement (%)
- Implementation complexity (low/medium/high)
- Tools needed (sheets_fix, sheets_advanced, sheets_appsscript)

**â¬œ Step 4: Implement Optimizations**

Execute your strategy:
- Always preview before applying
- Implement highest-impact optimizations first
- Test after each change

**â¬œ Step 5: Measure Improvements**

Re-run performance analysis:
\`\`\`
sheets_analyze action:"analyze_performance"
  spreadsheetId:"${spreadsheetId}"
  checkFormulas:true
  checkVolatility:true
\`\`\`

Calculate improvements:
- Operation time improvement: ___%
- Formula recalc improvement: ___%
- Quality improvement: ___pts

## Optimization Techniques

**Technique 1: Consolidate Volatile Functions**
Before: =NOW() in 50 cells
After: =NOW() in 1 cell, reference elsewhere
Improvement: ~98% reduction in recalculations

**Technique 2: Replace ARRAYFORMULA with QUERY**
Before: =ARRAYFORMULA(VLOOKUP(...))
After: =QUERY(...)
Improvement: ~6x faster

**Technique 3: Add Named Ranges**
Before: Direct cell references (break on column insert)
After: Named ranges (stable, faster lookup)
Improvement: ~20% faster formula evaluation

**Technique 4: Batch Operations**
Before: Multiple individual writes
After: sheets_transaction
Improvement: ~80% quota savings, ~90% time savings

**Technique 5: Helper Columns**
Before: Complex nested formulas
After: Intermediate calculations in helper columns
Improvement: ~50% faster, easier to debug

## Scoring

**Bonus Points:**
- >60% improvement across all metrics: +20 pts
- <3 operations to achieve goal: +10 pts
- Zero quality degradation: +5 pts

## ğŸ¯ Profiler Tips

1. Use analyze_performance first (don't guess)
2. Focus on high-impact optimizations
3. Measure after EACH change (track progress)
4. Don't over-optimize (diminishing returns)
5. Balance performance vs maintainability

## ğŸš¨ Common Pitfalls

- âŒ Optimizing low-impact areas
- âŒ Breaking formulas while optimizing
- âŒ Not testing after each change
- âŒ Over-complicating solutions

## Ready to Profile?

Run your baseline measurement and tell me what you find. I'll track your progress and reveal optimization opportunities.

Timer starts now! â±ï¸`,
            },
          },
        ],
      };
    }
  );

  server.registerPrompt(
    'scenario_multi_user',
    {
      description: 'ğŸ‘¥ Resolve concurrent editing conflicts',
      argsSchema: ScenarioMultiUserPromptArgsSchema,
    },
    async ({ spreadsheetId, scenario }) => {
      const selectedScenario = scenario || 'conflict_resolution';

      return {
        messages: [
          {
            role: 'user' as const,
            content: {
              type: 'text' as const,
              text: `# ğŸ‘¥ Multi-User Collaboration Scenario

**Spreadsheet:** ${spreadsheetId}
**Scenario:** ${selectedScenario.replace(/_/g, ' ').toUpperCase()}

${
  selectedScenario === 'conflict_resolution'
    ? `
## Situation

You manage a sales tracking spreadsheet used by 12 team members simultaneously. Recent issues:

1. Sales reps accidentally overwriting each other's data
2. Manager-only summary formulas being deleted
3. No way to see who changed what
4. Can't revert incorrect changes

## Stakeholders

**Sales Reps (10 users)**
- Need: Add their own sales data
- Problem: Can't tell if they're overwriting someone else's entry
- Frustration: "I spent 30 minutes entering data and someone deleted it"

**Sales Manager (1 user)**
- Need: Protected summary section with formulas
- Problem: Reps accidentally edit summary formulas
- Frustration: "I have to fix broken formulas every day"

**Admin (1 user)**
- Need: Full control + audit trail
- Problem: No visibility into who changed what
- Frustration: "I can't find who deleted important data"

## Your Task

Design a solution that:
1. Prevents accidental overwrites
2. Protects manager formulas
3. Maintains audit trail
4. Allows easy rollback

## Available Tools

**Option 1: Protected Ranges**
\`\`\`
sheets_advanced action:"add_protected_range"
  spreadsheetId:"${spreadsheetId}"
  range:"Summary!A1:Z100"
  editors:["manager@company.com"]
\`\`\`

**Option 2: Version Snapshots**
\`\`\`
sheets_collaborate action:"create_snapshot"
  spreadsheetId:"${spreadsheetId}"
  description:"Before daily edit session"
\`\`\`

**Option 3: Change Notifications**
\`\`\`
sheets_webhook action:"register"
  spreadsheetId:"${spreadsheetId}"
  events:["SHEET_MODIFIED"]
  handler:"notify_admin"
\`\`\`

**Option 4: Confirmation Workflows**
\`\`\`
sheets_confirm action:"require_confirmation"
  operation:"delete_rows"
  minimumRows:5
\`\`\`

## Solution Requirements

**Must have:**
- Row-level protection (each rep owns their rows)
- Summary section fully protected
- Automatic daily snapshots
- Change notification to admin

**Nice to have:**
- Visual indicators of protected cells
- Undo history (last 10 changes)
- Conflict detection warnings

## Your Deliverable

1. **Architecture Diagram** (text format showing layers)
2. **Implementation Plan** (step-by-step with tool calls)
3. **Trade-offs** (pros/cons of your approach)
4. **Rollback Strategy** (how to revert if issues arise)

## Example Architecture

\`\`\`
Layer 1: Base Protection
â”œâ”€ Protect Summary!A1:Z100 (Manager only)
â”œâ”€ Protect Headers Row 1 (Admin only)
â””â”€ Sales Data Rows 2-1000 (Any authenticated user)

Layer 2: Row Ownership
â”œâ”€ Each rep assigned specific rows
â”œâ”€ Can edit only their rows
â””â”€ Read-only access to others' rows

Layer 3: Audit & Rollback
â”œâ”€ Daily snapshots (keep 30 days)
â”œâ”€ Webhook notifications on delete >5 rows
â””â”€ Version history tracking

Layer 4: User Experience
â”œâ”€ Color-code rows by owner
â”œâ”€ Add "Owner" column
â””â”€ Confirmation on bulk delete
\`\`\`

Start designing your solution!
`
    : ''
}${
                selectedScenario === 'protection_strategy'
                  ? `
## Situation

A financial planning spreadsheet contains:
- Public sections (everyone can edit)
- Team sections (specific teams only)
- Executive sections (C-suite only)
- Formula sections (read-only for all)

Currently: No protection, frequent accidental edits, formulas broken weekly.

## Requirements

**Public Sections:**
- Input forms (rows 5-100)
- Anyone can add data
- Cannot delete others' data

**Team Sections:**
- Marketing data (rows 200-300, marketing team only)
- Sales data (rows 400-500, sales team only)
- Engineering data (rows 600-700, engineering team only)

**Executive Sections:**
- Budget summary (rows 900-950, C-suite only)
- Financial projections (rows 1000-1050, CFO only)

**Formula Sections:**
- Summary calculations (columns Z-AE, read-only)
- Validation formulas (column AZ, read-only)

## Your Task

Design granular protection strategy:
1. Map all protection zones
2. Assign editor groups
3. Implement protection rules
4. Test access levels

## Implementation Pattern

\`\`\`
# Step 1: Public Input Protection
sheets_advanced action:"add_protected_range"
  range:"A5:Y100"
  warningOnly:true
  description:"Public input area"

# Step 2: Team-Specific Protection
sheets_advanced action:"add_protected_range"
  range:"A200:Y300"
  editors:["marketing@company.com", "marketing-team@company.com"]
  description:"Marketing team data"

# Step 3: Executive Protection
sheets_advanced action:"add_protected_range"
  range:"A900:Y950"
  editors:["ceo@company.com", "cfo@company.com", "coo@company.com"]
  description:"Executive summary"

# Step 4: Formula Protection
sheets_advanced action:"add_protected_range"
  range:"Z:AE"
  description:"Calculation formulas - READ ONLY"
\`\`\`

Design your comprehensive protection strategy!
`
                  : ''
              }${
                selectedScenario === 'version_control'
                  ? `
## Situation

A project tracking spreadsheet is updated by multiple team members throughout the day:

**Current Problems:**
1. No way to see what changed between morning and evening
2. Can't revert to "last known good state"
3. No approval process for major changes
4. Lost data from accidental bulk deletes

**Requirements:**
1. Automatic snapshots every 4 hours
2. Manual snapshots before major changes
3. Easy comparison between versions
4. One-click rollback to any snapshot
5. Approval workflow for changes affecting >100 cells

## Your Task

Implement version control system:
1. Snapshot schedule
2. Comparison mechanism
3. Rollback procedure
4. Approval workflow

## Implementation Pattern

**Pattern 1: Scheduled Snapshots**
\`\`\`
sheets_appsscript action:"time_trigger"
  interval:"4 hours"
  operation:"create_snapshot"
  spreadsheetId:"${spreadsheetId}"
\`\`\`

**Pattern 2: Pre-Change Snapshot**
\`\`\`
# Before any major operation
sheets_collaborate action:"create_snapshot"
  description:"Before data import - \${new Date()}"

# Perform operation
sheets_data action:"write" ...

# Verify
sheets_analyze action:"scout"

# Rollback if needed
if (quality_dropped) {
  sheets_collaborate action:"restore_snapshot"
  snapshotId:"latest"
}
\`\`\`

**Pattern 3: Version Comparison**
\`\`\`
sheets_collaborate action:"compare_versions"
  baseSnapshot:"morning-snapshot"
  targetSnapshot:"current"

Returns:
- Cells changed: 247
- Rows added: 12
- Rows deleted: 3
- Formulas modified: 8
\`\`\`

**Pattern 4: Approval Workflow**
\`\`\`
sheets_confirm action:"require_approval"
  threshold:100
  approvers:["manager@company.com"]
  message:"Change affects \${cellCount} cells. Manager approval required."
\`\`\`

Build your version control workflow!
`
                  : ''
              }

## ğŸ¯ Success Criteria

Your solution should:
âœ… Solve the stated problem completely
âœ… Be implementable with available tools
âœ… Consider all stakeholder needs
âœ… Include rollback/recovery plan
âœ… Be maintainable long-term

## ğŸ“Š Evaluation

I'll assess your solution on:
- **Completeness**: Addresses all requirements (40pts)
- **Feasibility**: Can be implemented with ServalSheets (30pts)
- **Trade-offs**: Acknowledges pros/cons (20pts)
- **Rollback**: Clear recovery strategy (10pts)

## ğŸ’¡ Collaboration Tips

1. Start with stakeholder analysis (who needs what)
2. Map protection zones before implementing
3. Test with sample users (different roles)
4. Document for future maintainers
5. Plan for edge cases (what if...)

Present your solution and I'll provide feedback on feasibility and improvements! ğŸ‘¥`,
            },
          },
        ],
      };
    }
  );

  // === CONTEXT-AWARE AND CHAINED WORKFLOW PROMPTS (Phase 3: Improvement Plan) ===

  server.registerPrompt(
    'auto_analyze',
    {
      description:
        'ğŸ”® Auto-detect spreadsheet type and suggest best workflows, resources, and prompts',
      argsSchema: AutoAnalyzePromptArgsSchema,
    },
    async ({ spreadsheetId }) => {
      return {
        messages: [
          {
            role: 'user' as const,
            content: {
              type: 'text' as const,
              text: `ğŸ”® Auto-Analyzing spreadsheet: ${spreadsheetId}

## Analysis Workflow

1. **Get Metadata**
   - sheets_core action "get" to retrieve spreadsheet metadata
   - Examine sheet names and structure

2. **Analyze Structure**
   - sheets_analyze action "analyze_structure" for detailed analysis
   - Identify column headers and data patterns

3. **Detect Spreadsheet Type**
   Based on detected patterns, classify as one of:
   - **Budget**: Has "income", "expense", "balance", "category" columns
   - **CRM**: Has "name", "email", "phone", "company", "deal" columns
   - **Inventory**: Has "SKU", "quantity", "price", "stock", "reorder" columns
   - **Project**: Has "task", "status", "due date", "assignee", "milestone" columns
   - **Sales**: Has "customer", "product", "amount", "date", "stage" columns
   - **Marketing**: Has "campaign", "channel", "spend", "impressions", "conversions" columns

## After Detection, Recommend

### Knowledge Resources
Based on the detected type, suggest the 3 most relevant:
- knowledge:// resources (templates, formulas, schemas)

### Best Prompts
Suggest prompts that match the spreadsheet type:
- For Budget: setup_budget, performance_audit
- For CRM: setup_collaboration, diagnose_errors
- For Inventory: bulk_import, transform_data
- For Project: create_report, setup_collaboration
- For Sales: create_visualization, performance_audit
- For Marketing: create_report, clean_data

### Optimal Tool Sequences
Provide a recommended workflow based on common patterns:
- Read â†’ Analyze â†’ Recommend â†’ Apply

## Output Format

Provide your findings in this format:
1. **Detected Type**: [Type with confidence %]
2. **Key Columns**: [List of detected headers]
3. **Recommended Knowledge**: [3 resource URIs]
4. **Suggested Prompts**: [3 prompt names]
5. **Next Steps**: [Recommended action sequence]`,
            },
          },
        ],
      };
    }
  );

  server.registerPrompt(
    'full_setup',
    {
      description: 'ğŸš€ Complete spreadsheet setup: create, format, populate, and share',
      argsSchema: FullSetupPromptArgsSchema,
    },
    async ({ type, name, collaborators }) => {
      const typeTemplates: Record<string, { knowledge: string; formulas: string }> = {
        budget: { knowledge: 'templates/finance', formulas: 'formulas/financial' },
        crm: { knowledge: 'templates/crm', formulas: 'formulas/lookup' },
        inventory: { knowledge: 'templates/inventory', formulas: 'formulas/lookup' },
        project: { knowledge: 'templates/project', formulas: 'formulas/datetime' },
        sales: { knowledge: 'templates/sales', formulas: 'formulas/financial' },
        marketing: { knowledge: 'templates/marketing', formulas: 'formulas/advanced' },
      };

      const defaultTemplate = { knowledge: 'templates/finance', formulas: 'formulas/financial' };
      const template = typeTemplates[type as keyof typeof typeTemplates] ?? defaultTemplate;
      const knowledgePath = template.knowledge;
      const formulasPath = template.formulas;
      const collaboratorList = collaborators?.length
        ? collaborators.join(', ')
        : '(none specified)';

      return {
        messages: [
          {
            role: 'user' as const,
            content: {
              type: 'text' as const,
              text: `ğŸš€ Full Setup: Creating ${type.toUpperCase()} spreadsheet "${name}"

## 5-Step Workflow

### Step 1: Create Spreadsheet
- Use sheets_core action "create" with title "${name}"
- Remember the spreadsheetId for subsequent steps

### Step 2: Apply Template
- Read template from knowledge:///${knowledgePath}.json
- Use sheets_composite action "setup_sheet" with the schema
- This creates all necessary sheets and headers

### Step 3: Add Formulas
- Read formulas from knowledge:///${formulasPath}.json
- Apply relevant formulas to calculation columns
- Focus on:
  - Summary calculations
  - Conditional aggregations
  - Cross-reference lookups

### Step 4: Format
- Use sheets_format action "apply_preset" for headers
- Add conditional formatting for key metrics:
  - Green for positive values
  - Red for negative values
  - Yellow for warnings
- Auto-fit columns using sheets_dimensions

### Step 5: Share
- Collaborators: ${collaboratorList}
${
  collaborators?.length
    ? `- Use sheets_collaborate action "share_add" for each collaborator
- Set appropriate permissions based on role`
    : '- Skip sharing (no collaborators specified)'
}

## Safety Measures
- Use sheets_confirm before any destructive operations
- Create snapshot after setup complete using sheets_history action "create_snapshot"
- Verify all formulas work correctly

## Resources to Reference
- Template: knowledge:///${knowledgePath}.json
- Formulas: knowledge:///${formulasPath}.json
- Guide: servalsheets://guides/batching-strategies

Ready to execute this setup workflow? I'll guide you through each step.`,
            },
          },
        ],
      };
    }
  );

  server.registerPrompt(
    'audit_security',
    {
      description: 'ğŸ”’ Security and permissions audit for a spreadsheet',
      argsSchema: AuditSecurityPromptArgsSchema,
    },
    async ({ spreadsheetId }) => {
      return {
        messages: [
          {
            role: 'user' as const,
            content: {
              type: 'text' as const,
              text: `ğŸ”’ Security Audit for Spreadsheet: ${spreadsheetId}

## Audit Checklist

### 1. Permissions Review
- Use sheets_collaborate action "share_list" to get current permissions
- Analyze:
  - [ ] Who has Owner access?
  - [ ] Who has Editor access?
  - [ ] Who has Viewer access?
  - [ ] Are there any link-shared permissions?
  - [ ] Are there any domain-wide permissions?

### 2. Protection Analysis
- Use sheets_advanced action "protection_list" to check protections
- Review:
  - [ ] Which sheets are protected?
  - [ ] Which ranges are protected?
  - [ ] Who can edit protected areas?
  - [ ] Are there any unprotected sensitive areas?

### 3. Data Sensitivity Check
- Use sheets_analyze action "analyze_structure" for content analysis
- Flag potential PII:
  - [ ] Email addresses
  - [ ] Phone numbers
  - [ ] Social security numbers
  - [ ] Financial account numbers
  - [ ] Addresses

### 4. History and Audit Trail
- Use sheets_collaborate action "version_list" to check revision history
- Verify:
  - [ ] Is revision history enabled?
  - [ ] Who made recent changes?
  - [ ] Are there any suspicious modifications?

## Security Recommendations

Based on findings, suggest:
1. **Permission adjustments** (who should have access)
2. **Protection additions** (what should be protected)
3. **Data handling** (PII masking or removal)
4. **Audit improvements** (notification setup)

## Reference
- Guide: knowledge:///masterclass/security-compliance-master.json
- Patterns: servalsheets://decisions/tool-selection

Please proceed with this security audit and provide a comprehensive report.`,
            },
          },
        ],
      };
    }
  );

  server.registerPrompt(
    'compare_spreadsheets',
    {
      description: 'ğŸ” Compare and diff two spreadsheets',
      argsSchema: CompareSpreadsheetPromptArgsSchema,
    },
    async ({ spreadsheetId1, spreadsheetId2 }) => {
      return {
        messages: [
          {
            role: 'user' as const,
            content: {
              type: 'text' as const,
              text: `ğŸ” Comparing Spreadsheets

**Spreadsheet A:** ${spreadsheetId1}
**Spreadsheet B:** ${spreadsheetId2}

## Comparison Workflow

### Step 1: Get Metadata
- Use sheets_core action "get" on both spreadsheets
- Compare:
  - [ ] Spreadsheet titles
  - [ ] Sheet names and count
  - [ ] Last modified dates

### Step 2: Compare Structure
- Use sheets_analyze action "analyze_structure" on both
- Compare:
  - [ ] Column headers
  - [ ] Data types per column
  - [ ] Row counts
  - [ ] Named ranges

### Step 3: Compare Data
For each matching sheet:
- Use sheets_data action "batch_read" to get data ranges
- Compare:
  - [ ] Cell values (identify differences)
  - [ ] Formulas (identify formula changes)
  - [ ] Formatting differences (if visible)

### Step 4: Identify Differences

Output a comparison report:

\`\`\`
COMPARISON REPORT
=================

Structural Differences:
- Sheets only in A: [list]
- Sheets only in B: [list]
- Column differences: [details]

Data Differences:
- Modified cells: [count]
- Added rows: [count in A] vs [count in B]
- Deleted rows: [comparison]

Formula Changes:
- [Cell]: [Old Formula] â†’ [New Formula]

Summary:
- Overall similarity: [percentage]
- Key changes: [summary]
\`\`\`

## Use Cases
- Version comparison (before/after changes)
- Template vs instance comparison
- Data migration validation
- Parallel edit reconciliation

Please proceed with this comparison and provide a detailed diff report.`,
            },
          },
        ],
      };
    }
  );
}
